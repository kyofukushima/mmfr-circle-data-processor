import streamlit as st
import pandas as pd
import io
import time
import os
import chardet
import re
import datetime
import hashlib
from openpyxl import load_workbook
from openpyxl.utils import get_column_letter
from openpyxl.styles import Border, Side, Alignment, Font
from copy import copy

# ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼ˆãƒ†ã‚¹ãƒˆæ™‚ã«åˆ‡ã‚Šæ›¿ãˆå¯èƒ½ï¼‰
TEMPLATE_FILE = os.getenv('TEMPLATE_FILE', 'template.xlsx')

def normalize_value(raw_value):
    """æ¬ æå€¤ã‚’çµ±ä¸€çš„ã«å‡¦ç†ã™ã‚‹å…±é€šé–¢æ•°
    
    Args:
        raw_value: å‡¦ç†å¯¾è±¡ã®å€¤
    
    Returns:
        str: æ­£è¦åŒ–ã•ã‚ŒãŸå€¤ï¼ˆç©ºæ–‡å­—åˆ—ã¾ãŸã¯æ–‡å­—åˆ—ï¼‰
    """
    if pd.isna(raw_value):
        return ''
    value = str(raw_value).strip()
    if value in ['nan', 'None', '<NA>']:
        return ''
    return value

def detect_encoding(file_content):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ¤œå‡ºã™ã‚‹"""
    result = chardet.detect(file_content)
    return result['encoding'], result['confidence']

def process_binary_columns(df):
    """0/1ã®å€¤ã‚’æŒã¤åˆ—ã®å¤‰æ›å‡¦ç†ã‚’è¡Œã†
    
    Args:
        df (pd.DataFrame): å‡¦ç†å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    
    Returns:
        tuple: (å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ , å‡¦ç†å†…å®¹ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ )
    """
    # å¤‰æ›å¯¾è±¡ã®åˆ—ã‚’å®šç¾©
    target_patterns = [
        'å¯¾è±¡å¹´é½¢',  # å¯¾è±¡å¹´é½¢ã‚’å«ã‚€åˆ—
        'è¦ä¼šè²»',
        'å†Šå­æ²è¼‰å¯',
        'HPæ²è¼‰å¯',
        'ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿æ²è¼‰å¯'
    ]
    
    # å¤‰æ›å¯¾è±¡ã®åˆ—åã‚’æŠ½å‡º
    target_columns = []
    for pattern in target_patterns:
        matched_columns = [col for col in df.columns if pattern in str(col)]
        target_columns.extend(matched_columns)
    
    # é‡è¤‡ã‚’å‰Šé™¤
    target_columns = list(dict.fromkeys(target_columns))
    
    # å‡¦ç†å†…å®¹ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã¨ã—ã¦ä½œæˆ
    process_df = pd.DataFrame(columns=['å‡¦ç†å†…å®¹', 'å¯¾è±¡åˆ—'])
    if target_columns:
        for col in target_columns:
            # åˆ—ã‚’æ–‡å­—åˆ—å‹ã«å¤‰æ›
            df[col] = df[col].astype(str)
            # 0ã‚’ç©ºæ¬„ã«å¤‰æ›
            df[col] = df[col].replace('0', '')
            # 1ã‚’â—‹ã«å¤‰æ›
            df[col] = df[col].replace('1', 'â—‹')
        
        # å‡¦ç†å†…å®¹ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
        process_df = pd.DataFrame({
            'å‡¦ç†å†…å®¹': ['0ã‚’ç©ºæ¬„ã«å¤‰æ›ãŠã‚ˆã³1ã‚’â—‹ã«å¤‰æ›'],
            'å¯¾è±¡åˆ—': [', '.join(target_columns)]
        })
    
    return df, process_df

def add_location_column(circle_data,df_f):
    """
    å ´æ‰€åˆ—ã®è¿½åŠ æ–½è¨­æƒ…å ±ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã™ã‚‹
    Såˆ—ã€Œæ´»å‹•å ´æ‰€ã€ã®æ–½è¨­åç§°ã‚’å‚è€ƒã«ã€æ–½è¨­æƒ…å ±ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰Jåˆ—ã€Œå ´æ‰€ã€ã‚’æŠ½å‡ºãƒ»çªåˆã™ã‚‹
    Jåˆ—ã€Œå ´æ‰€ã€ã‹ã‚‰æŠ½å‡ºãƒ»çªåˆã—ãŸæƒ…å ±ã‚’AYåˆ—ã®ã€Œå ´æ‰€ã€ã«å…¥åŠ›ã™ã‚‹
    Såˆ—ã€Œæ´»å‹•å ´æ‰€ã€ã«æ–½è¨­åç§°ãŒãªã‹ã£ãŸã‚Šã€è‚²å…ã‚µãƒ¼ã‚¯ãƒ«ç­‰åœ°åŒºè¡¨ç¤ºç”¨ã€‘â—‹â—‹åŒºã‚’æŒ‡å®šã—ã¦ã„ã‚‹å ´åˆã«ã¯AYåˆ—ã®ã€Œå ´æ‰€ã€ã¯ç©ºæ¬„ã«ãªã‚‹ãŒã€ã“ã®å ´åˆç©ºæ¬„ã«ãªã‚‹ã®ãŒæ­£ã€‚
    
    Returns:
        tuple: (å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ , å‡¦ç†å†…å®¹ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ )
    """
    circle_data['å ´æ‰€'] = circle_data['æ´»å‹•å ´æ‰€'].map(df_f.set_index('æ–½è¨­å')['å ´æ‰€'])
    
    # å‡¦ç†å†…å®¹ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
    process_df = pd.DataFrame({
        'å‡¦ç†å†…å®¹': ['æ´»å‹•å ´æ‰€ã®æ–½è¨­åç§°ã‹ã‚‰å ´æ‰€æƒ…å ±ã‚’æŠ½å‡ºãƒ»çªåˆ'],
        'å¯¾è±¡åˆ—': ['æ´»å‹•å ´æ‰€ â†’ å ´æ‰€']
    })
    
    return circle_data, process_df

def check_data_consistency(circle_data, last_month_data):
    """
    è‚²å…ã‚µãƒ¼ã‚¯ãƒ«ãƒ‡ãƒ¼ã‚¿ã¨å…ˆæœˆåˆ†ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹
    
    Args:
        circle_data (pd.DataFrame): è‚²å…ã‚µãƒ¼ã‚¯ãƒ«ãƒ‡ãƒ¼ã‚¿
        last_month_data (pd.DataFrame): å…ˆæœˆåˆ†ãƒ‡ãƒ¼ã‚¿
    
    Returns:
        None
    
    Raises:
        st.stop(): ãƒ‡ãƒ¼ã‚¿ã®ä¸ä¸€è‡´ãŒã‚ã‚‹å ´åˆã«å‡¦ç†ã‚’åœæ­¢
    """
    # ã‚¹ãƒ©ãƒƒã‚°ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯
    circle_duplicates = circle_data[circle_data['ã‚¹ãƒ©ãƒƒã‚°'].duplicated()]['ã‚¹ãƒ©ãƒƒã‚°'].unique()
    last_month_duplicates = last_month_data[last_month_data['ã‚¹ãƒ©ãƒƒã‚°'].duplicated()]['ã‚¹ãƒ©ãƒƒã‚°'].unique()
    
    error_messages = []
    
    if len(circle_duplicates) > 0:
        error_messages.append("### è‚²å…ã‚µãƒ¼ã‚¯ãƒ«ãƒ‡ãƒ¼ã‚¿å†…ã§é‡è¤‡ã—ã¦ã„ã‚‹ã‚¹ãƒ©ãƒƒã‚°:")
        for slug in circle_duplicates:
            circle_names = circle_data[circle_data['ã‚¹ãƒ©ãƒƒã‚°'] == slug]['ã‚µãƒ¼ã‚¯ãƒ«å'].tolist()
            error_messages.append(f"- ã‚¹ãƒ©ãƒƒã‚°: {slug}")
            for name in circle_names:
                error_messages.append(f"  - ã‚µãƒ¼ã‚¯ãƒ«å: {name}")
    
    if len(last_month_duplicates) > 0:
        error_messages.append("\n### å…ˆæœˆåˆ†ãƒ‡ãƒ¼ã‚¿å†…ã§é‡è¤‡ã—ã¦ã„ã‚‹ã‚¹ãƒ©ãƒƒã‚°:")
        for slug in last_month_duplicates:
            circle_names = last_month_data[last_month_data['ã‚¹ãƒ©ãƒƒã‚°'] == slug]['ã‚µãƒ¼ã‚¯ãƒ«å'].tolist()
            error_messages.append(f"- ã‚¹ãƒ©ãƒƒã‚°: {slug}")
            for name in circle_names:
                error_messages.append(f"  - ã‚µãƒ¼ã‚¯ãƒ«å: {name}")
    
    # ã‚¹ãƒ©ãƒƒã‚°ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
    circle_slugs = set(circle_data['ã‚¹ãƒ©ãƒƒã‚°'])
    last_month_slugs = set(last_month_data['ã‚¹ãƒ©ãƒƒã‚°'])
    
    # è‚²å…ã‚µãƒ¼ã‚¯ãƒ«ãƒ‡ãƒ¼ã‚¿ã«ã®ã¿å­˜åœ¨ã™ã‚‹ã‚¹ãƒ©ãƒƒã‚°
    only_in_circle = circle_slugs - last_month_slugs
    # å…ˆæœˆåˆ†ãƒ‡ãƒ¼ã‚¿ã«ã®ã¿å­˜åœ¨ã™ã‚‹ã‚¹ãƒ©ãƒƒã‚°
    only_in_last_month = last_month_slugs - circle_slugs
    
    if only_in_circle:
        error_messages.append("\n### å…ˆæœˆåˆ†ãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã—ãªã„ã‚¹ãƒ©ãƒƒã‚°:")
        for slug in only_in_circle:
            circle_name = circle_data[circle_data['ã‚¹ãƒ©ãƒƒã‚°'] == slug]['ã‚µãƒ¼ã‚¯ãƒ«å'].iloc[0]
            error_messages.append(f"- ã‚¹ãƒ©ãƒƒã‚°: {slug} (ã‚µãƒ¼ã‚¯ãƒ«å: {circle_name})")
    
    if only_in_last_month:
        error_messages.append("\n### è‚²å…ã‚µãƒ¼ã‚¯ãƒ«ãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã—ãªã„ã‚¹ãƒ©ãƒƒã‚°:")
        for slug in only_in_last_month:
            circle_name = last_month_data[last_month_data['ã‚¹ãƒ©ãƒƒã‚°'] == slug]['ã‚µãƒ¼ã‚¯ãƒ«å'].iloc[0]
            error_messages.append(f"- ã‚¹ãƒ©ãƒƒã‚°: {slug} (ã‚µãƒ¼ã‚¯ãƒ«å: {circle_name})")
    
    if error_messages:
        st.error("""
        ### ãƒ‡ãƒ¼ã‚¿ã®ä¸ä¸€è‡´ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ
        
        {}
        
        â€» ã‚¹ãƒ©ãƒƒã‚°ã®é‡è¤‡ã‚„ä¸ä¸€è‡´ã‚’ä¿®æ­£ã—ã¦ã‹ã‚‰å†åº¦å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚
        """.format('\n'.join(error_messages)))
        st.stop()

def add_account_columns(circle_data, last_month_data):
    """
    å…ˆæœˆåˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±ã‚’è¿½åŠ ã™ã‚‹
    
    Args:
        circle_data (pd.DataFrame): è‚²å…ã‚µãƒ¼ã‚¯ãƒ«ãƒ‡ãƒ¼ã‚¿
        last_month_data (pd.DataFrame): å…ˆæœˆåˆ†ã®ãƒ‡ãƒ¼ã‚¿
    
    Returns:
        tuple: (å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ , å‡¦ç†å†…å®¹ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ )
    """
    # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆé–¢é€£åˆ—ã®è¿½åŠ 
    account_columns = ['ï½±ï½¶ï½³ï¾ï¾„ç™ºè¡Œæœ‰ç„¡', 'ï½±ï½¶ï½³ï¾ï¾„ç™ºè¡Œå¹´æœˆ', 'ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç™ºè¡Œã®ç™»éŒ²ç”¨ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹']
    
    try:
        for col in account_columns:
            # ã‚¹ãƒ©ãƒƒã‚°ã‚’ã‚­ãƒ¼ã¨ã—ã¦ãƒãƒƒãƒ”ãƒ³ã‚°
            mapping_dict = last_month_data.set_index('ã‚¹ãƒ©ãƒƒã‚°')[col].to_dict()
            circle_data[col] = circle_data['ã‚¹ãƒ©ãƒƒã‚°'].map(mapping_dict)
    except Exception as e:
        st.error(f"""
        ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±ã®è¿½åŠ ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚
        ã‚¨ãƒ©ãƒ¼å†…å®¹: {str(e)}
        
        ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼š
        1. ã‚¹ãƒ©ãƒƒã‚°ã«é‡è¤‡ãŒãªã„ã“ã¨
        2. å¿…è¦ãªåˆ—ï¼ˆ{', '.join(account_columns)}ï¼‰ãŒå…ˆæœˆåˆ†ãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã™ã‚‹ã“ã¨
        """)
        st.stop()
    
    # å‡¦ç†å†…å®¹ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
    process_df = pd.DataFrame({
        'å‡¦ç†å†…å®¹': ['å…ˆæœˆåˆ†ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±ã‚’è¿½åŠ '],
        'å¯¾è±¡åˆ—': [', '.join(account_columns)]
    })
    
    return circle_data, process_df

def validate_csv_file(csv_file):
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼ã‚’è¡Œã†"""
    # åŸºæœ¬çš„ãªã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒªã‚¹ãƒˆ
    encodings = ['utf-8', 'shift-jis', 'cp932', 'euc-jp']
    detected_encoding = None
    debug_info = []
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’èª­ã¿è¾¼ã‚€
    file_content = csv_file.read()
    csv_file.seek(0)
    
    # chardetã«ã‚ˆã‚‹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¤œå‡º
    detected_enc, confidence = detect_encoding(file_content)
    if detected_enc:
        encodings.insert(0, detected_enc)
        debug_info.append(f"chardetãŒæ¤œå‡ºã—ãŸã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°: {detected_enc} (ä¿¡é ¼åº¦: {confidence:.2f})")
    
    # é‡è¤‡ã‚’å‰Šé™¤
    encodings = list(dict.fromkeys(encodings))
    
    for encoding in encodings:
        try:
            debug_info.append(f"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° {encoding} ã§è©¦è¡Œä¸­...")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ³ã‚¿ã‚’å…ˆé ­ã«æˆ»ã™
            csv_file.seek(0)
            
            # æœ€åˆã®æ•°è¡Œã‚’èª­ã‚“ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ãƒã‚§ãƒƒã‚¯
            sample = file_content.decode(encoding)
            if not sample.strip():
                debug_info.append(f"  â†’ ãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™")
                continue
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ³ã‚¿ã‚’å…ˆé ­ã«æˆ»ã™
            csv_file.seek(0)
            
            # CSVã¨ã—ã¦èª­ã¿è¾¼ã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            df = pd.read_csv(io.StringIO(sample), encoding=encoding)
            if df.empty:
                debug_info.append(f"  â†’ ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
                continue
            if len(df.columns) == 0:
                debug_info.append(f"  â†’ åˆ—ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                continue
                
            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ³ã‚¿ã‚’å…ˆé ­ã«æˆ»ã™
            csv_file.seek(0)
            detected_encoding = encoding
            debug_info.append(f"  â†’ æ­£å¸¸ã«èª­ã¿è¾¼ã‚ã¾ã—ãŸ")
            return df, detected_encoding, debug_info
            
        except UnicodeDecodeError as e:
            debug_info.append(f"  â†’ ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {str(e)}")
            continue
        except pd.errors.EmptyDataError:
            debug_info.append(f"  â†’ ç©ºã®CSVãƒ•ã‚¡ã‚¤ãƒ«")
            raise ValueError("CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™")
        except Exception as e:
            debug_info.append(f"  â†’ ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼: {str(e)}")
            continue
    
    error_msg = "CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’èªè­˜ã§ãã¾ã›ã‚“ã€‚ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã®å½¢å¼ã§ä¿å­˜ã—ã¦ãã ã•ã„ï¼šUTF-8ã€Shift-JISã€CP932ã€EUC-JP"
    if st.session_state.get('debug_mode', False):
        error_msg += "\n\nãƒ‡ãƒãƒƒã‚°æƒ…å ±:\n" + "\n".join(debug_info)
    raise ValueError(error_msg)

def copy_cell_format(source_cell, target_cell):
    """ã‚»ãƒ«ã®æ›¸å¼ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹"""
    if source_cell.has_style:
        target_cell.font = copy(source_cell.font)
        target_cell.border = copy(source_cell.border)
        target_cell.fill = copy(source_cell.fill)
        target_cell.number_format = copy(source_cell.number_format)
        target_cell.protection = copy(source_cell.protection)
        target_cell.alignment = copy(source_cell.alignment)

def validate_excel_file(excel_file):
    """å…ˆæœˆåˆ†ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼ã¨èª­ã¿è¾¼ã¿ã‚’è¡Œã†
    
    Args:
        excel_file: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸExcelãƒ•ã‚¡ã‚¤ãƒ«
    
    Returns:
        pd.DataFrame: èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    """
    try:
        # Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ï¼ˆ2,3è¡Œç›®ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰
        df = pd.read_excel(excel_file, skiprows=[1,2])
        
        # åŸºæœ¬çš„ãªæ¤œè¨¼
        if df.empty:
            raise ValueError("Excelãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            
        if len(df.columns) == 0:
            raise ValueError("Excelãƒ•ã‚¡ã‚¤ãƒ«ã«åˆ—ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼ã®å­˜åœ¨ç¢ºèª
        if df.columns.isna().any():
            raise ValueError("ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã«ç©ºã®åˆ—åãŒå­˜åœ¨ã—ã¾ã™")
        
        return df
        
    except pd.errors.EmptyDataError:
        raise ValueError("Excelãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™")
    except Exception as e:
        raise ValueError(f"Excelãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

def hide_columns(worksheet):
    """ç‰¹å®šã®åˆ—ã‚’éè¡¨ç¤ºã«ã™ã‚‹
    
    Args:
        worksheet: å¯¾è±¡ã®ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆ
    """
    # éè¡¨ç¤ºã«ã™ã‚‹åˆ—åã®ãƒªã‚¹ãƒˆ
    columns_to_hide = [
        'ã‚¹ãƒ©ãƒƒã‚°',
        'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹',
        'å‚åŠ è€…ã®æ¡ä»¶(å¦Šå¨ å¾ŒåŠ)',
        'å‚åŠ è€…ã®æ¡ä»¶(å‡ºç”£)',
        'å‚åŠ è€…ã®æ¡ä»¶(1æ­³å¾ŒåŠ)',
        'å‚åŠ è€…ã®æ¡ä»¶(2æ­³å¾ŒåŠ)',
        'ç”³è¾¼æ–¹æ³•å‚™è€ƒ',
        'æ´»å‹•æ—¥_å–¶æ¥­æ™‚é–“ãƒ©ãƒ™ãƒ«',
        'æ´»å‹•æ—¥_å–¶æ¥­æ›œæ—¥ãƒ©ãƒ™ãƒ«',
        'ä»£è¡¨è€…',
        'å›£ä½“å'
    ]
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‹ã‚‰åˆ—ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
    header_row = 1  # ãƒ˜ãƒƒãƒ€ãƒ¼ã¯1è¡Œç›®ã«ã‚ã‚‹
    for column in worksheet.iter_cols(min_row=header_row, max_row=header_row):
        if column[0].value in columns_to_hide:
            col_letter = get_column_letter(column[0].column)
            worksheet.column_dimensions[col_letter].hidden = True

def add_borders(worksheet, start_row, end_row, start_col, end_col):
    """ãƒ‡ãƒ¼ã‚¿ç¯„å›²ã«æ ç·šã‚’è¿½åŠ ã™ã‚‹
    
    Args:
        worksheet: å¯¾è±¡ã®ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆ
        start_row: é–‹å§‹è¡Œï¼ˆ1å§‹ã¾ã‚Šï¼‰
        end_row: çµ‚äº†è¡Œï¼ˆ1å§‹ã¾ã‚Šï¼‰
        start_col: é–‹å§‹åˆ—ï¼ˆ1å§‹ã¾ã‚Šï¼‰
        end_col: çµ‚äº†åˆ—ï¼ˆ1å§‹ã¾ã‚Šï¼‰
    """
    # æ ç·šã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’å®šç¾©
    thin_border = Border(
        left=Side(style='thin'),
        right=Side(style='thin'),
        top=Side(style='thin'),
        bottom=Side(style='thin')
    )
    
    # æŒ‡å®šç¯„å›²ã®å„ã‚»ãƒ«ã«æ ç·šã‚’è¨­å®š
    for row in range(start_row, end_row + 1):
        for col in range(start_col, end_col + 1):
            cell = worksheet.cell(row=row, column=col)
            cell.border = thin_border

def find_data_range(worksheet):
    """ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹ç¯„å›²ã‚’ç‰¹å®šã™ã‚‹
    
    Args:
        worksheet: å¯¾è±¡ã®ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆ
    
    Returns:
        tuple: (æœ€çµ‚è¡Œ, æœ€çµ‚åˆ—)
    """
    max_row = 1
    max_col = 1
    
    # æœ€çµ‚è¡Œã‚’ç‰¹å®š
    for row in worksheet.iter_rows():
        if any(cell.value is not None for cell in row):
            max_row = row[0].row
    
    # æœ€çµ‚åˆ—ã‚’ç‰¹å®š
    for col in worksheet.iter_cols():
        if any(cell.value is not None for cell in col):
            max_col = col[0].column
    
    return max_row, max_col

def set_row_height_and_format(worksheet, start_row, end_row, height=20):
    """è¡Œã®é«˜ã•ã‚’è¨­å®šã—ã€ã‚»ãƒ«ã®æ›¸å¼ã‚’è¨­å®šã™ã‚‹
    
    Args:
        worksheet: å¯¾è±¡ã®ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆ
        start_row: é–‹å§‹è¡Œï¼ˆ1å§‹ã¾ã‚Šï¼‰
        end_row: çµ‚äº†è¡Œï¼ˆ1å§‹ã¾ã‚Šï¼‰
        height: è¡Œã®é«˜ã•ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 20ï¼‰
    """
    # ã‚»ãƒ«ã®æ›¸å¼è¨­å®šï¼ˆæŠ˜ã‚Šè¿”ã—æœ‰åŠ¹ã€å·¦æƒãˆï¼‰
    alignment = Alignment(
        wrap_text=True,  # æŠ˜ã‚Šè¿”ã—
        horizontal='left',  # å·¦æƒãˆ
        vertical='center'  # ç¸¦æ–¹å‘ã¯ä¸­å¤®æƒãˆ
    )
    
    # ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
    font = Font(
        name='ãƒ¡ã‚¤ãƒªã‚ª',  # ãƒ•ã‚©ãƒ³ãƒˆå
        size=12,         # ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚º
    )
    
    # æŒ‡å®šç¯„å›²ã®å„è¡Œã«å¯¾ã—ã¦è¨­å®š
    for row in range(start_row, end_row + 1):
        # è¡Œã®é«˜ã•ã‚’è¨­å®š
        worksheet.row_dimensions[row].height = height
        
        # ãã®è¡Œã®å„ã‚»ãƒ«ã®æ›¸å¼ã‚’è¨­å®š
        for cell in worksheet[row]:
            cell.alignment = alignment
            cell.font = font

def setup_conditional_formatting(worksheet):
    """æ¡ä»¶ä»˜ãæ›¸å¼ã‚’è¨­å®šã™ã‚‹
    
    Args:
        worksheet: å¯¾è±¡ã®ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆ
    """
    from openpyxl.formatting.rule import Rule
    from openpyxl.styles import PatternFill
    from openpyxl.styles.differential import DifferentialStyle
    
    # è‰²ã®å®šç¾©
    red_fill = PatternFill(start_color='FFFF0000', end_color='FFFF0000', fill_type='solid')
    yellow_fill = PatternFill(start_color='FFFFFF00', end_color='FFFFFF00', fill_type='solid')
    green_fill = PatternFill(start_color='FF00FF00', end_color='FF00FF00', fill_type='solid')
    
    # ã‚¹ã‚¿ã‚¤ãƒ«ã®å®šç¾©
    red_style = DifferentialStyle(fill=red_fill)
    yellow_style = DifferentialStyle(fill=yellow_fill)
    green_style = DifferentialStyle(fill=green_fill)
    
    # æ¡ä»¶ä»˜ãæ›¸å¼ã®ãƒªã‚¹ãƒˆ
    conditional_rules = [
        {
            'name': 'ã‚¹ãƒ©ãƒƒã‚°ã®å·®åˆ†æ¤œå‡º',
            'description': 'ã‚¹ãƒ©ãƒƒã‚°ãŒç©ºã€ã¾ãŸã¯å…¥åŠ›ã•ã‚Œã¦ã„ã‚‹ãŒoriginalã«è¦‹ã¤ã‹ã‚‰ãªã„ã‚‚ã®ã‚’æ¤œå‡º',
            'formula': 'OR($B1="",ISERROR(MATCH($B1,INDIRECT("original!B1:B1048576"),0)))',
            'range': 'B1:B1048576',
            'style': red_style
        },
        # è¿½åŠ ã®æ¡ä»¶ä»˜ãæ›¸å¼ã¯ã“ã“ã«è¿½åŠ 
                 {
             'name': 'å¤‰æ›´ç®‡æ‰€ã®æ¤œå‡º',
             'description': 'åŒã˜ã‚¹ãƒ©ãƒƒã‚°ã‚’æŒã¤è¡Œã®åŒã˜åˆ—ã®ã‚»ãƒ«ã‚’æ¯”è¼ƒã€€â‡’ è©²å½“ã™ã‚‹ã‚»ãƒ«ã ã‘é»„è‰²ãç€è‰²',
             'formula': 'A1<>INDIRECT("original!"&ADDRESS(MATCH($B1,INDIRECT("original!B1:B1048576"),0),COLUMN(),4,1))',
             'range': 'A1:ZZ1048576',
             'style': yellow_style
         },
         {
             'name': 'è¿½åŠ è¡Œã®æ¤œå‡º',
             'description': 'å…¥åŠ›ã•ã‚Œã¦ã„ã‚‹ã‚¹ãƒ©ãƒƒã‚°ãŒoriginalã«è¦‹ã¤ã‹ã‚‰ãªã„ãŠã‚ˆã³ã‚µãƒ¼ã‚¯ãƒ«åãŒoriginalã«è¦‹ã¤ã‹ã‚‰ãªã„',
             'formula': 'OR(ISERROR(MATCH($B1,INDIRECT("original!B1:B1048576"),0)),ISERROR(MATCH($C1,INDIRECT("original!C1:C1048576"),0)))',
             'range': 'A1:ZZ1048576',
             'style': green_style
         }
    ]
    
    # æ¡ä»¶ä»˜ãæ›¸å¼ã‚’é©ç”¨
    for rule_config in conditional_rules:
        rule = Rule(
            type="expression",
            formula=[rule_config['formula']],
            stopIfTrue=True,
            dxf=rule_config['style']
        )
        worksheet.conditional_formatting.add(rule_config['range'], rule)
        
        # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰æ™‚ã«è¨­å®šå†…å®¹ã‚’å‡ºåŠ›
        if st.session_state.get('debug_mode', False):
            st.info(f"æ¡ä»¶ä»˜ãæ›¸å¼ã‚’è¨­å®š: {rule_config['name']} - {rule_config['description']}")

def process_files(circle_data, facility_data=None, last_month_data=None):
    """Pandasã‚’ä½¿ç”¨ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†"""
    start_time = time.time() if st.session_state.get('debug_mode', False) else None
    
    # å‡¦ç†å†…å®¹ã‚’è¨˜éŒ²ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
    process_df = pd.DataFrame(columns=['å‡¦ç†å†…å®¹', 'å¯¾è±¡åˆ—'])
    
    # 0/1ã®å€¤ã‚’æŒã¤åˆ—ã®å¤‰æ›å‡¦ç†
    circle_data, binary_process_df = process_binary_columns(circle_data)
    if not binary_process_df.empty:
        process_df = pd.concat([process_df, binary_process_df], ignore_index=True)
    
    # å ´æ‰€åˆ—ã®è¿½åŠ 
    circle_data, location_process_df = add_location_column(circle_data,facility_data)
    process_df = pd.concat([process_df, location_process_df], ignore_index=True)
    
    # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±ã®è¿½åŠ 
    circle_data, account_process_df = add_account_columns(circle_data, last_month_data)
    process_df = pd.concat([process_df, account_process_df], ignore_index=True)
    
    # å‡¦ç†å†…å®¹ã®è¡¨ç¤º
    if not process_df.empty:
        with st.expander("å‡¦ç†å†…å®¹ã‚’ç¢ºèªã™ã‚‹"):
            st.dataframe(process_df, use_container_width=True, hide_index=True)
    
    # å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¡¨ç¤º
    with st.expander("å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç¢ºèªã™ã‚‹"):
        st.dataframe(circle_data, use_container_width=True)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
    output = io.BytesIO()
    template_wb = load_workbook(TEMPLATE_FILE)
    template_ws = template_wb.active
    
    # ã‚·ãƒ¼ãƒˆåã‚’'original'ã«å¤‰æ›´
    template_ws.title = 'original'
    
    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®å†…å®¹ã‚’ãã®ã¾ã¾ã‚³ãƒ”ãƒ¼
    template_wb.save(output)
    output.seek(0)
    
    # ä¿å­˜ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†åº¦é–‹ã
    wb = load_workbook(output)
    original_ws = wb['original']
    
    # CSVãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãè¾¼ã‚€ï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’é™¤ãï¼‰
    if len(circle_data) > 0:  # ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿å‡¦ç†
        # CSVã®åˆ—æ•°ãŒãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®åˆ—æ•°ã‚’è¶…ãˆã¦ã„ãªã„ã‹ãƒã‚§ãƒƒã‚¯
        if len(circle_data.columns) > template_ws.max_column:
            raise ValueError(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ—æ•°ï¼ˆ{len(circle_data.columns)}åˆ—ï¼‰ãŒãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®åˆ—æ•°ï¼ˆ{template_ws.max_column}åˆ—ï¼‰ã‚’è¶…ãˆã¦ã„ã¾ã™ã€‚")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ‹¬ã§æ›¸ãè¾¼ã‚€
        data_values = circle_data.values
        for row_idx, row in enumerate(data_values, start=4):  # 4è¡Œç›®ã‹ã‚‰é–‹å§‹
            for col_idx, value in enumerate(row, start=1):
                cell = original_ws.cell(row=row_idx, column=col_idx)
                cell.value = value
                # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®åŒã˜ä½ç½®ã®ã‚»ãƒ«ã‹ã‚‰æ›¸å¼ã‚’ã‚³ãƒ”ãƒ¼
                template_cell = template_ws.cell(row=row_idx, column=col_idx)
                copy_cell_format(template_cell, cell)
        
        # ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹ç¯„å›²ã‚’ç‰¹å®š
        max_row, max_col = find_data_range(original_ws)
        
        # ãƒ‡ãƒ¼ã‚¿éƒ¨åˆ†ã«æ ç·šã‚’è¿½åŠ ï¼ˆ1è¡Œç›®ã‹ã‚‰æœ€çµ‚è¡Œã¾ã§ï¼‰
        add_borders(original_ws, 1, max_row, 1, max_col)
        
        # è¡Œã®é«˜ã•ã¨ã‚»ãƒ«æ›¸å¼ã‚’è¨­å®šï¼ˆ4è¡Œç›®ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿æœ€çµ‚è¡Œã¾ã§ï¼‰
        set_row_height_and_format(original_ws, 4, max_row)
    
    # ç‰¹å®šã®åˆ—ã‚’éè¡¨ç¤ºã«ã™ã‚‹
    hide_columns(original_ws)
    
    # ã‚·ãƒ¼ãƒˆã‚’ã‚³ãƒ”ãƒ¼ã—ã¦'circle_info'ã‚·ãƒ¼ãƒˆã‚’ä½œæˆ
    circle_info_ws = wb.copy_worksheet(original_ws)
    circle_info_ws.title = 'circle_info'
    
    # originalã‚·ãƒ¼ãƒˆã‚’éè¡¨ç¤ºã«ã™ã‚‹
    original_ws.sheet_state = 'hidden'
    
    # æ¡ä»¶ä»˜ãæ›¸å¼ã®è¨­å®š
    setup_conditional_formatting(circle_info_ws)
    
    # ã‚·ãƒ¼ãƒˆã®ã‚°ãƒ«ãƒ¼ãƒ—ã‚’è§£é™¤
    for ws in wb.worksheets:
        ws.sheet_view.tabSelected = False
    
    # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚·ãƒ¼ãƒˆã‚’æ˜ç¤ºçš„ã«è¨­å®šï¼ˆcircle_infoã‚·ãƒ¼ãƒˆã‚’ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã«ï¼‰
    wb.active = circle_info_ws
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
    output.seek(0)
    wb.save(output)
    
    processing_time = time.time() - start_time if st.session_state.get('debug_mode', False) else None
    
    output.seek(0)
    return output, processing_time

def initialize_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–"""
    if 'debug_mode' not in st.session_state:
        st.session_state.debug_mode = False
    
    # ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆç”¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹
    if 'validation_completed' not in st.session_state:
        st.session_state.validation_completed = False
    if 'validated_data' not in st.session_state:
        st.session_state.validated_data = None
    if 'import_data_created' not in st.session_state:
        st.session_state.import_data_created = False
    if 'import_files' not in st.session_state:
        st.session_state.import_files = None
    if 'formatted_data' not in st.session_state:
        st.session_state.formatted_data = None
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®å¤‰åŒ–ã‚’è¿½è·¡ã™ã‚‹ãŸã‚ã®ãƒ­ã‚°
    if 'session_log' not in st.session_state:
        st.session_state.session_log = []
    
    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®è¿½è·¡ç”¨
    if 'uploaded_files_hash' not in st.session_state:
        st.session_state.uploaded_files_hash = {
            'excel': None,
            'facility': None,
            'user': None
        }

def log_session_state_change(action, details=None):
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®å¤‰åŒ–ã‚’ãƒ­ã‚°ã«è¨˜éŒ²"""
    import datetime
    
    if 'session_log' not in st.session_state:
        st.session_state.session_log = []
    
    log_entry = {
        'timestamp': datetime.datetime.now().strftime("%H:%M:%S.%f")[:-3],
        'action': action,
        'details': details or {},
        'session_state': {
            'validation_completed': st.session_state.get('validation_completed', False),
            'validated_data': st.session_state.get('validated_data') is not None,
            'import_data_created': st.session_state.get('import_data_created', False),
            'import_files': st.session_state.get('import_files') is not None,
            'formatted_data': st.session_state.get('formatted_data') is not None,
        }
    }
    
    st.session_state.session_log.append(log_entry)
    
    # ãƒ­ã‚°ã®æœ€å¤§æ•°ã‚’åˆ¶é™ï¼ˆãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’æŠ‘åˆ¶ï¼‰
    if len(st.session_state.session_log) > 50:
        st.session_state.session_log = st.session_state.session_log[-50:]

def show_session_state_debug():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º"""
    if not st.session_state.get('debug_mode', False):
        return
    
    with st.expander("ğŸ” ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ãƒ‡ãƒãƒƒã‚°æƒ…å ±", expanded=False):
        # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹
        st.subheader("ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹")
        current_state = {
            'validation_completed': st.session_state.get('validation_completed', False),
            'validated_data': st.session_state.get('validated_data') is not None,
            'import_data_created': st.session_state.get('import_data_created', False),
            'import_files': st.session_state.get('import_files') is not None,
            'formatted_data': st.session_state.get('formatted_data') is not None,
        }
        
        col1, col2 = st.columns(2)
        with col1:
            for key, value in current_state.items():
                status_icon = "âœ…" if value else "âŒ"
                st.write(f"{status_icon} {key}: {value}")
        
        with col2:
            if st.session_state.get('validated_data') is not None:
                st.write(f"ğŸ“Š validated_data è¡Œæ•°: {len(st.session_state.validated_data)}")
            if st.session_state.get('import_files') is not None:
                st.write(f"ğŸ“ import_files æ•°: {len(st.session_state.import_files)}")
            if st.session_state.get('formatted_data') is not None:
                st.write(f"ğŸ“‹ formatted_data è¡Œæ•°: {len(st.session_state.formatted_data)}")
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®å¤‰åŒ–ãƒ­ã‚°
        if st.session_state.get('session_log'):
            st.subheader("ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹å¤‰åŒ–ãƒ­ã‚°")
            
            # ãƒ­ã‚°ã‚’ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§è¡¨ç¤º
            log_data = []
            for log_entry in reversed(st.session_state.session_log[-10:]):  # æœ€æ–°10ä»¶
                log_data.append({
                    'æ™‚åˆ»': log_entry['timestamp'],
                    'ã‚¢ã‚¯ã‚·ãƒ§ãƒ³': log_entry['action'],
                    'æ¤œè¨¼å®Œäº†': "âœ…" if log_entry['session_state']['validation_completed'] else "âŒ",
                    'ãƒ‡ãƒ¼ã‚¿ä½œæˆå®Œäº†': "âœ…" if log_entry['session_state']['import_data_created'] else "âŒ",
                    'ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨': "âœ…" if log_entry['session_state']['import_files'] else "âŒ",
                    'è©³ç´°': str(log_entry['details']) if log_entry['details'] else ""
                })
            
            if log_data:
                st.dataframe(pd.DataFrame(log_data), use_container_width=True)
            
            # ãƒ­ã‚°ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
            if st.button("ãƒ­ã‚°ã‚’ã‚¯ãƒªã‚¢", key="clear_session_log"):
                st.session_state.session_log = []
                # st.rerun()ã¯å‰Šé™¤ - ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒªã‚»ãƒƒãƒˆã‚’é˜²ããŸã‚ã€æ¬¡å›ã®è‡ªå‹•ãƒªãƒ­ãƒ¼ãƒ‰ã§åæ˜ ã•ã‚Œã‚‹
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼CSVä½œæˆãƒ‡ãƒãƒƒã‚°æƒ…å ±
        if hasattr(st.session_state, 'user_csv_debug_info') and st.session_state.user_csv_debug_info:
            st.subheader("ãƒ¦ãƒ¼ã‚¶ãƒ¼æ–°è¦è¿½åŠ CSVä½œæˆãƒ‡ãƒãƒƒã‚°æƒ…å ±")
            debug_info = st.session_state.user_csv_debug_info
            
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"ğŸ“Š å…¨ãƒ‡ãƒ¼ã‚¿è¡Œæ•°: {debug_info['total_rows']}")
                st.write(f"âœ… ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç™ºè¡Œæœ‰ç„¡ãŒâ—‹ã®è¡Œæ•°: {debug_info['account_issued_count']}")
            
            with col2:
                st.write(f"ğŸ“§ ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹è¨˜è¼‰ã®è¡Œæ•°: {debug_info['email_filled_count']}")
                st.write(f"ğŸ¯ ä¸¡æ–¹ã®æ¡ä»¶ã‚’æº€ãŸã™è¡Œæ•°: {debug_info['new_accounts_count']}")
            
            # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯åŸå› èª¿æŸ»ã®è¡¨ç¤º
            if debug_info['new_accounts_count'] > 0:
                st.write("âœ… **æ¡ä»¶ã‚’æº€ãŸã™ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒ«:**")
                if debug_info['new_accounts_sample'] is not None:
                    st.dataframe(debug_info['new_accounts_sample'], use_container_width=True)
            else:
                st.write("âŒ **æ¡ä»¶ã‚’æº€ãŸã•ãªã„ç†ç”±ã®èª¿æŸ»:**")
                
                if debug_info['account_values'] is not None:
                    st.write("**ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç™ºè¡Œæœ‰ç„¡åˆ—ã®å€¤ã®åˆ†å¸ƒ:**")
                    st.write(debug_info['account_values'])
                

            
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
            if st.button("ãƒ¦ãƒ¼ã‚¶ãƒ¼CSVãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’ã‚¯ãƒªã‚¢", key="clear_user_csv_debug"):
                del st.session_state.user_csv_debug_info
                # st.rerun()ã¯å‰Šé™¤ - ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒªã‚»ãƒƒãƒˆã‚’é˜²ããŸã‚ã€æ¬¡å›ã®è‡ªå‹•ãƒªãƒ­ãƒ¼ãƒ‰ã§åæ˜ ã•ã‚Œã‚‹

def reset_import_session_state():
    """ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆé–¢é€£ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ"""
    log_session_state_change("reset_import_session_state", {
        'before_validation_completed': st.session_state.get('validation_completed', False),
        'before_import_data_created': st.session_state.get('import_data_created', False)
    })
    
    st.session_state.validation_completed = False
    st.session_state.validated_data = None
    st.session_state.import_data_created = False
    st.session_state.import_files = None
    st.session_state.formatted_data = None
    st.session_state.balloons_shown = False  # ãƒãƒ«ãƒ¼ãƒ³è¡¨ç¤ºãƒ•ãƒ©ã‚°ã‚‚ãƒªã‚»ãƒƒãƒˆ
    
    # è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚‚ã‚¯ãƒªã‚¢
    if 'account_date_warning' in st.session_state:
        del st.session_state.account_date_warning
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆè­¦å‘Šã‚‚ã‚¯ãƒªã‚¢
    if 'user_creation_warning' in st.session_state:
        del st.session_state.user_creation_warning
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¿®æ­£æƒ…å ±ã‚‚ã‚¯ãƒªã‚¢
    if 'user_modification_details' in st.session_state:
        del st.session_state.user_modification_details

def check_file_changed(file, file_type):
    """ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤‰æ›´ã•ã‚ŒãŸã‹ãƒã‚§ãƒƒã‚¯ã—ã€å¤‰æ›´ã•ã‚ŒãŸå ´åˆã®ã¿ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
    
    Args:
        file: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«
        file_type: ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ— ('excel', 'facility', 'user')
    
    Returns:
        bool: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆTrue
    """
    if file is None:
        return False
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‹ã‚‰ãƒãƒƒã‚·ãƒ¥ã‚’ç”Ÿæˆ
    file_content = file.read()
    file.seek(0)  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ³ã‚¿ã‚’å…ˆé ­ã«æˆ»ã™
    file_hash = hashlib.md5(file_content).hexdigest()
    
    # å‰å›ã®ãƒãƒƒã‚·ãƒ¥ã¨æ¯”è¼ƒ
    previous_hash = st.session_state.uploaded_files_hash.get(file_type)
    
    if previous_hash != file_hash:
        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆ
        st.session_state.uploaded_files_hash[file_type] = file_hash
        log_session_state_change(f"{file_type}_file_changed", {
            'filename': file.name,
            'previous_hash': previous_hash,
            'new_hash': file_hash
        })
        return True
    else:
        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤‰æ›´ã•ã‚Œã¦ã„ãªã„å ´åˆ
        log_session_state_change(f"{file_type}_file_unchanged", {
            'filename': file.name,
            'hash': file_hash
        })
        return False

def validate_order_column(df):
    """é †ç•ªåˆ—ã®å€¤ã‚’æ¤œè¨¼ã™ã‚‹
    
    Args:
        df (pd.DataFrame): æ¤œè¨¼å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    
    Raises:
        ValueError: é †ç•ªåˆ—ã«æ•°å€¤ä»¥å¤–ã®å€¤ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆ
    """
    if 'é †ç•ª' not in df.columns:
        return
    
    # æ•°å€¤ä»¥å¤–ã®å€¤ã‚’å«ã‚€è¡Œã‚’æ¤œå‡º
    non_numeric_rows = df[pd.to_numeric(df['é †ç•ª'], errors='coerce').isna()]
    if not non_numeric_rows.empty:
        error_message = ["### ã‚¨ãƒ©ãƒ¼: ã€Œé †ç•ªã€åˆ—ã«æ•°å€¤ä»¥å¤–ã®å€¤ãŒå«ã¾ã‚Œã¦ã„ã¾ã™"]
        for _, row in non_numeric_rows.iterrows():
            error_message.append(f"- ã‚µãƒ¼ã‚¯ãƒ«å: {row['ã‚µãƒ¼ã‚¯ãƒ«å']}")
            error_message.append(f"  - ã‚¹ãƒ©ãƒƒã‚°: {row['ã‚¹ãƒ©ãƒƒã‚°']}")
            error_message.append(f"  - é †ç•ª: {row['é †ç•ª']}")
        
        raise ValueError("\n".join(error_message))
    
    # 1æœªæº€ã®å€¤ã‚’å«ã‚€è¡Œã‚’æ¤œå‡º
    invalid_rows = df[pd.to_numeric(df['é †ç•ª']) < 1]
    if not invalid_rows.empty:
        warning_message = ["### è­¦å‘Š: ã€Œé †ç•ªã€åˆ—ã«1æœªæº€ã®å€¤ãŒå«ã¾ã‚Œã¦ã„ã‚‹è¡ŒãŒã‚ã‚Šã¾ã™"]
        for _, row in invalid_rows.iterrows():
            warning_message.append(f"- ã‚µãƒ¼ã‚¯ãƒ«å: {row['ã‚µãƒ¼ã‚¯ãƒ«å']}")
            warning_message.append(f"  - ã‚¹ãƒ©ãƒƒã‚°: {row['ã‚¹ãƒ©ãƒƒã‚°']}")
            warning_message.append(f"  - é †ç•ª: {row['é †ç•ª']}")
        
        st.warning("\n".join(warning_message))

def show_modification_excel_page():
    """ãƒ‡ãƒ¼ã‚¿ä¿®æ­£ç”¨ã‚¨ã‚¯ã‚»ãƒ«ä½œæˆãƒšãƒ¼ã‚¸ã®è¡¨ç¤º"""
    st.header("ãƒ‡ãƒ¼ã‚¿ä¿®æ­£ç”¨ã‚¨ã‚¯ã‚»ãƒ«ä½œæˆ")
    
    # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰æ™‚ã®ã¿è¡¨ç¤ºã•ã‚Œã‚‹æƒ…å ±
    if st.session_state.debug_mode:
        st.write("### ãƒ‡ãƒãƒƒã‚°æƒ…å ±")
        st.write("ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ãŒæœ‰åŠ¹ã§ã™")
    
    st.write("### ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    
    # è‚²å…ã‚µãƒ¼ã‚¯ãƒ«CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    csv_file = st.file_uploader("è‚²å…ã‚µãƒ¼ã‚¯ãƒ«CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„", type=['csv'])
    if csv_file:
        try:
            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼ã¨èª­ã¿è¾¼ã¿
            circle_data, encoding, debug_info = validate_csv_file(csv_file)
            
            # é †ç•ªåˆ—ã®æ¤œè¨¼ï¼ˆæ¤œè¨¼ã®å¿…è¦æ€§ã«ã¤ã„ã¦ç¢ºèªä¸­ã€‚å¿…è¦ã§ã‚ã‚Œã°ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆè§£é™¤ï¼‰
            # validate_order_column(circle_data)
            
            st.success("è‚²å…ã‚µãƒ¼ã‚¯ãƒ«CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£å¸¸ã«èª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸ")
            with st.expander("è‚²å…ã‚µãƒ¼ã‚¯ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã™ã‚‹"):
                st.dataframe(circle_data, use_container_width=True)
        except ValueError as e:
            st.error(f"è‚²å…ã‚µãƒ¼ã‚¯ãƒ«CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ©ãƒ¼: {str(e)}")
        except Exception as e:
            st.error(f"è‚²å…ã‚µãƒ¼ã‚¯ãƒ«CSVãƒ•ã‚¡ã‚¤ãƒ«ã®äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    # æ–½è¨­æƒ…å ±CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    facility_csv_file = st.file_uploader("æ–½è¨­æƒ…å ±CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„", type=['csv'])
    if facility_csv_file:
        try:
            # æ–½è¨­æƒ…å ±CSVãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼ã¨èª­ã¿è¾¼ã¿
            facility_data, facility_encoding, facility_debug_info = validate_csv_file(facility_csv_file)
            st.success("æ–½è¨­æƒ…å ±CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£å¸¸ã«èª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸ")
            with st.expander("æ–½è¨­æƒ…å ±ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã™ã‚‹"):
                st.dataframe(facility_data, use_container_width=True)
        except ValueError as e:
            st.error(f"æ–½è¨­æƒ…å ±CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ©ãƒ¼: {str(e)}")
        except Exception as e:
            st.error(f"æ–½è¨­æƒ…å ±CSVãƒ•ã‚¡ã‚¤ãƒ«ã®äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    # å…ˆæœˆåˆ†ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆExcelãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    last_month_file = st.file_uploader("å…ˆæœˆåˆ†ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆExcelãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã‚’é¸æŠã—ã¦ãã ã•ã„", type=['xlsx'])
    if last_month_file:
        try:
            # Excelãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼ã¨èª­ã¿è¾¼ã¿
            last_month_data = validate_excel_file(last_month_file)
            
            # ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ï¼ˆã‚¹ãƒ©ãƒƒã‚°ã®ä¸€è‡´ç¢ºèªï¼‰
            if 'circle_data' in locals() and circle_data is not None:
                check_data_consistency(circle_data, last_month_data)
            
            st.success("å…ˆæœˆåˆ†ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£å¸¸ã«èª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸ")
            with st.expander("å…ˆæœˆæƒ…å ±ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã™ã‚‹"):
                st.dataframe(last_month_data, use_container_width=True)
        except ValueError as e:
            st.error(f"å…ˆæœˆåˆ†ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ©ãƒ¼: {str(e)}")
        except Exception as e:
            st.error(f"å…ˆæœˆåˆ†ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã®äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    # å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ãŒæƒã£ã¦ã„ã‚‹ã‹ç¢ºèª
    all_data_ready = (
        'circle_data' in locals() and circle_data is not None and
        'facility_data' in locals() and facility_data is not None and
        'last_month_data' in locals() and last_month_data is not None
    )
    
    if all_data_ready:
        st.success("å…¨ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£å¸¸ã«èª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸã€‚å‡¦ç†ã‚’é–‹å§‹ã§ãã¾ã™ã€‚")
        
        # è‡ªæ²»ä½“åã®å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¿½åŠ ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼šåŒ—ä¹å·å¸‚æ§˜ï¼‰
        municipality = st.text_input("è‡ªæ²»ä½“å", value="åŒ—ä¹å·å¸‚æ§˜", help="ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ç”¨ã•ã‚Œã‚‹è‡ªæ²»ä½“åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        
        if st.button("å‡¦ç†é–‹å§‹"):
            try:
                # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚’å®Ÿè¡Œ
                output, proc_time = process_files(
                    circle_data,
                    facility_data=facility_data,
                    last_month_data=last_month_data
                )
                
                # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰æ™‚ã®ã¿å‡¦ç†æ™‚é–“ã¨è¡Œæ•°ã‚’è¡¨ç¤º
                if st.session_state.get('debug_mode', False):
                    st.info(f"å‡¦ç†æ™‚é–“: {proc_time:.3f}ç§’")
                    template_wb = load_workbook(TEMPLATE_FILE)
                    template_ws = template_wb.active
                    st.info(f"å‡¦ç†ã—ãŸãƒ‡ãƒ¼ã‚¿è¡Œæ•°: {len(circle_data)-1}è¡Œ")  # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’é™¤ã
                    st.info(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ—æ•°: {len(circle_data.columns)}åˆ—")
                    st.info(f"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ—æ•°: {template_ws.max_column}åˆ—")
                
                # ç¾åœ¨ã®æœˆã‚’å–å¾—
                current_month = datetime.datetime.now().month
                
                # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
                file_name = f"ã€{municipality}ã€‘è‚²å…ã‚µãƒ¼ã‚¯ãƒ«ç­‰ä¿®æ­£ç”¨ãƒ‡ãƒ¼ã‚¿ï¼ˆ{current_month}æœˆåˆ†ï¼‰.xlsx"
                
                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
                st.download_button(
                    label="å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=output,
                    file_name=file_name,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
                
                st.success("ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                
            except ValueError as e:
                st.error(str(e))
            except Exception as e:
                st.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

def validate_modification_status(main_data, original_data):
    """ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®æ¤œè¨¼
    
    Args:
        main_data (pd.DataFrame): ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿
        original_data (pd.DataFrame): å·®åˆ†æ¤œå‡ºç”¨ãƒ‡ãƒ¼ã‚¿
    
    Returns:
        pd.DataFrame: ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    """
    errors = []
    valid_statuses = ['ä¿®æ­£', 'æ–°è¦è¿½åŠ ', 'æ²è¼‰é †', 'å‰Šé™¤']
    
    for idx, row in main_data.iterrows():
        error_list = []
        status = normalize_value(row.get('ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦', ''))
        
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å€¤ã®æ¤œè¨¼
        if status != '' and status not in valid_statuses:
            error_list.append(f"ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦åˆ—ã«ã€æ¬¡ã®å€¤ä»¥å¤–ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã™ã€‚(ä¿®æ­£ãƒ»æ–°è¦è¿½åŠ ãƒ»æ²è¼‰é †ãƒ»å‰Šé™¤)")
        
        # ä¿®æ­£ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®æ¤œè¨¼
        if status == 'ä¿®æ­£':
            slug = str(row.get('ã‚¹ãƒ©ãƒƒã‚°', '')).strip()
            if slug:
                # å·®åˆ†æ¤œå‡ºç”¨ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åŒã˜ã‚¹ãƒ©ãƒƒã‚°ã®è¡Œã‚’å–å¾—
                original_row = original_data[original_data['ã‚¹ãƒ©ãƒƒã‚°'] == slug]
                if not original_row.empty:
                    # ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦åˆ—ã¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆé–¢é€£åˆ—ä»¥å¤–ã®åˆ—ã§å·®åˆ†ã‚’ãƒã‚§ãƒƒã‚¯
                    excluded_columns = ['ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦', 'ï½±ï½¶ï½³ï¾ï¾„ç™ºè¡Œæœ‰ç„¡', 'ï½±ï½¶ï½³ï¾ï¾„ç™ºè¡Œå¹´æœˆ', 'ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç™ºè¡Œã®ç™»éŒ²ç”¨ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹']
                    check_columns = [col for col in main_data.columns if col not in excluded_columns]
                    has_difference = False
                    
                    for col in check_columns:
                        if col in original_row.columns:
                            main_value = normalize_value(row.get(col, ''))
                            original_value = normalize_value(original_row.iloc[0].get(col, ''))
                            
                            if main_value != original_value:
                                has_difference = True
                                break
                    
                    if not has_difference:
                        # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆé–¢é€£ã®ã¿ã®å¤‰æ›´ã®å ´åˆã¯ã‚¨ãƒ©ãƒ¼ã¨ã—ãªã„
                        if not is_only_account_related_change(row, original_data):
                            error_list.append("ä¿®æ­£ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€å€¤ãŒå¤‰æ›´ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # æ–°è¦è¿½åŠ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®æ¤œè¨¼
        elif status == 'æ–°è¦è¿½åŠ ':
            slug = normalize_value(row.get('ã‚¹ãƒ©ãƒƒã‚°', ''))
            if slug != '':
                error_list.append("æ–°è¦è¿½åŠ ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã‚¹ãƒ©ãƒƒã‚°åˆ—ã«å€¤ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã™")
        
        # æ²è¼‰é †ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®æ¤œè¨¼
        elif status == 'æ²è¼‰é †':
            slug = str(row.get('ã‚¹ãƒ©ãƒƒã‚°', '')).strip()
            if slug:
                original_row = original_data[original_data['ã‚¹ãƒ©ãƒƒã‚°'] == slug]
                if not original_row.empty:
                    main_order = normalize_value(row.get('é †ç•ª', ''))
                    original_order = normalize_value(original_row.iloc[0].get('é †ç•ª', ''))
                    
                    if main_order == original_order:
                        error_list.append("ã€Œæ²è¼‰é †ã€ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãŒæŒ¯ã‚‰ã‚Œã¦ã„ã¾ã™ãŒã€é †ç•ªãŒå¤‰ã‚ã£ã¦ã„ã¾ã›ã‚“")
        
        errors.append(', '.join(error_list) if error_list else '')
    
    return errors

def validate_empty_status(main_data, original_data):
    """ç©ºæ¬„ã®æ¤œè¨¼
    
    Args:
        main_data (pd.DataFrame): ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿
        original_data (pd.DataFrame): å·®åˆ†æ¤œå‡ºç”¨ãƒ‡ãƒ¼ã‚¿
    
    Returns:
        list: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ
    """
    errors = []
    
    for idx, row in main_data.iterrows():
        error_list = []
        status = normalize_value(row.get('ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦', ''))
        
        if status == '':  # ç©ºæ¬„ã¾ãŸã¯æ¬ æå€¤ã®å ´åˆ
            slug = str(row.get('ã‚¹ãƒ©ãƒƒã‚°', '')).strip()
            if slug:
                original_row = original_data[original_data['ã‚¹ãƒ©ãƒƒã‚°'] == slug]
                if not original_row.empty:
                    # ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦åˆ—ã¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆé–¢é€£åˆ—ä»¥å¤–ã®åˆ—ã§å·®åˆ†ã‚’ãƒã‚§ãƒƒã‚¯
                    excluded_columns = ['ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦', 'ï½±ï½¶ï½³ï¾ï¾„ç™ºè¡Œæœ‰ç„¡', 'ï½±ï½¶ï½³ï¾ï¾„ç™ºè¡Œå¹´æœˆ', 'ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç™ºè¡Œã®ç™»éŒ²ç”¨ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹']
                    check_columns = [col for col in main_data.columns if col not in excluded_columns]
                    changed_columns = []
                    
                    for col in check_columns:
                        if col in original_row.columns:
                            main_value = normalize_value(row.get(col, ''))
                            original_value = normalize_value(original_row.iloc[0].get(col, ''))
                            
                            if main_value != original_value:
                                changed_columns.append(col)
                    
                    if changed_columns:
                        error_list.append(f"ä¿®æ­£ã¨æ›¸ã‹ã‚Œã¦ã„ã¾ã›ã‚“ãŒã€{','.join(changed_columns)}ã®å€¤ãŒå¤‰æ›´ã•ã‚Œã¦ã„ã¾ã™")
        
        errors.append(', '.join(error_list) if error_list else '')
    
    return errors

def validate_machine_dependent_characters(main_data):
    """æ©Ÿç¨®ä¾å­˜æ–‡å­—ã®æ¤œè¨¼
    
    Args:
        main_data (pd.DataFrame): ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿
    
    Returns:
        list: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ
    """
    errors = []
    target_columns = ['ã‚µãƒ¼ã‚¯ãƒ«å', 'æ¦‚è¦', 'æ´»å‹•å ´æ‰€', 'ç”³è¾¼æ–¹æ³•', 'ä¼šè²»', 'æ´»å‹•æ—¥_å‚™è€ƒ', 
                     'å›£ä½“åï¼ˆãµã‚ŠãŒãªï¼‰', 'å°å­¦æ ¡åŒº', 'å°å­¦æ ¡åŒºï¼ˆãµã‚ŠãŒãªï¼‰', 'ä»£è¡¨è€…å', 
                     'ä»£è¡¨è€…åï¼ˆãµã‚ŠãŒãªï¼‰', 'ä»£è¡¨è€…ä½æ‰€', 'è¨˜å…¥è€…', 'å ´æ‰€']
    
    # æ©Ÿç¨®ä¾å­˜æ–‡å­—ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆä¸€éƒ¨ã®ä¾‹ï¼‰
    machine_dependent_chars = ['â‘ ', 'â‘¡', 'â‘¢', 'â‘£', 'â‘¤', 'â‘¥', 'â‘¦', 'â‘§', 'â‘¨', 'â‘©', 
                              'ã‰', 'ãŒ”', 'ãŒ˜', 'ãŒ§', 'ãŒƒ', 'ãŒ', 'ãŒ¦', 'ãŒ¢', 'ãŒ˜', 'ãŒ§']
    
    for idx, row in main_data.iterrows():
        error_list = []
        
        for col in target_columns:
            if col in main_data.columns:
                value = normalize_value(row.get(col, ''))
                
                if value:  # ç©ºæ¬„ã§ãªã„å ´åˆã®ã¿ãƒã‚§ãƒƒã‚¯
                    for char in machine_dependent_chars:
                        if char in value:
                            error_list.append(f"{col}åˆ—ã«æ©Ÿç¨®ä¾å­˜æ–‡å­—ãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
                            break
        
        errors.append(', '.join(error_list) if error_list else '')
    
    return errors

def validate_cell_line_breaks(main_data):
    """ã‚»ãƒ«å†…æ”¹è¡Œã®æ¤œè¨¼
    
    Args:
        main_data (pd.DataFrame): ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿
    
    Returns:
        list: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ
    """
    errors = []
    target_columns = ['ã‚µãƒ¼ã‚¯ãƒ«å', 'æ´»å‹•ç¨®åˆ¥', 'æ´»å‹•å ´æ‰€', 'ç”³è¾¼æ–¹æ³•', 'Eãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹', 'ä¼šè²»', 
                     'Webã‚µã‚¤ãƒˆ', 'æ´»å‹•æ—¥_å‚™è€ƒ', 'å›£ä½“åï¼ˆãµã‚ŠãŒãªï¼‰', 'å¹¼ç¨šåœ’ãƒ»ä¿è‚²åœ’ãƒã‚§ãƒƒã‚¯', 
                     'å°å­¦æ ¡åŒº', 'å°å­¦æ ¡åŒºï¼ˆãµã‚ŠãŒãªï¼‰', 'ä»£è¡¨è€…å', 'ä»£è¡¨è€…åï¼ˆãµã‚ŠãŒãªï¼‰', 
                     'ä»£è¡¨è€…ä½æ‰€', 'è¨˜å…¥è€…', 'å ´æ‰€']
    
    for idx, row in main_data.iterrows():
        error_list = []
        
        for col in target_columns:
            if col in main_data.columns:
                value = normalize_value(row.get(col, ''))
                
                if value and ('\n' in value or '\r' in value):
                    error_list.append(f"{col}åˆ—ã«ã‚»ãƒ«å†…æ”¹è¡ŒãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
        
        errors.append(', '.join(error_list) if error_list else '')
    
    return errors

def validate_prohibited_changes(main_data, original_data):
    """å¤‰æ›´ç¦æ­¢åˆ—ã®æ¤œè¨¼
    
    Args:
        main_data (pd.DataFrame): ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿
        original_data (pd.DataFrame): å·®åˆ†æ¤œå‡ºç”¨ãƒ‡ãƒ¼ã‚¿
    
    Returns:
        list: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ
    """
    errors = []
    prohibited_columns = ['ã‚¹ãƒ©ãƒƒã‚°', 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', 'å‚åŠ è€…ã®æ¡ä»¶(å¦Šå¨ å¾ŒåŠ)', 'å‚åŠ è€…ã®æ¡ä»¶(å‡ºç”£)', 
                         'å‚åŠ è€…ã®æ¡ä»¶(1æ­³å¾ŒåŠ)', 'å‚åŠ è€…ã®æ¡ä»¶(2æ­³å¾ŒåŠ)', 'ç”³è¾¼æ–¹æ³•å‚™è€ƒ', 
                         'æ´»å‹•æ—¥_å–¶æ¥­æ™‚é–“ãƒ©ãƒ™ãƒ«', 'ä»£è¡¨è€…', 'å›£ä½“å']
    
    for idx, row in main_data.iterrows():
        error_list = []
        status = normalize_value(row.get('ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦', ''))
        
        # æ–°è¦è¿½åŠ ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if status == 'æ–°è¦è¿½åŠ ':
            errors.append('')
            continue
        
        slug = str(row.get('ã‚¹ãƒ©ãƒƒã‚°', '')).strip()
        if slug:
            original_row = original_data[original_data['ã‚¹ãƒ©ãƒƒã‚°'] == slug]
            if not original_row.empty:
                changed_columns = []
                
                for col in prohibited_columns:
                    if col in main_data.columns and col in original_row.columns:
                        main_value = normalize_value(row.get(col, ''))
                        original_value = normalize_value(original_row.iloc[0].get(col, ''))
                        
                        if main_value != original_value:
                            changed_columns.append(col)
                
                if changed_columns:
                    error_list.append(f"{','.join(changed_columns)}ã®å€¤ãŒå¤‰æ›´ã•ã‚Œã¦ã„ã¾ã™")
        
        errors.append(', '.join(error_list) if error_list else '')
    
    return errors

def validate_consecutive_spaces(main_data):
    """é€£ç¶šã—ãŸç©ºç™½ã®æ¤œè¨¼
    
    Args:
        main_data (pd.DataFrame): ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿
    
    Returns:
        list: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ
    """
    errors = []
    target_columns = ['ã‚µãƒ¼ã‚¯ãƒ«å', 'æ¦‚è¦', 'æ´»å‹•å ´æ‰€', 'ç”³è¾¼æ–¹æ³•', 'ä¼šè²»', 'æ´»å‹•æ—¥_å‚™è€ƒ', 
                     'å›£ä½“åï¼ˆãµã‚ŠãŒãªï¼‰', 'å°å­¦æ ¡åŒº', 'å°å­¦æ ¡åŒºï¼ˆãµã‚ŠãŒãªï¼‰', 'ä»£è¡¨è€…å', 
                     'ä»£è¡¨è€…åï¼ˆãµã‚ŠãŒãªï¼‰', 'ä»£è¡¨è€…ä½æ‰€', 'è¨˜å…¥è€…', 'å ´æ‰€']
    
    for idx, row in main_data.iterrows():
        error_list = []
        
        for col in target_columns:
            if col in main_data.columns:
                value = normalize_value(row.get(col, ''))
                
                if value and '   ' in value:  # 3ã¤ä»¥ä¸Šã®é€£ç¶šã—ãŸç©ºç™½
                    error_list.append(f"{col}åˆ—ã«é€£ç¶šã—ãŸç©ºç™½ãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
        
        errors.append(', '.join(error_list) if error_list else '')
    
    return errors

def validate_alphanumeric(main_data):
    """åŠè§’è‹±æ•°ã®æ¤œè¨¼
    
    Args:
        main_data (pd.DataFrame): ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿
    
    Returns:
        list: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ
    """
    errors = []
    # Webã‚µã‚¤ãƒˆåˆ—ã‚’é™¤å¤–ï¼ˆURLæ¤œè¨¼ã§åˆ¥é€”å‡¦ç†ï¼‰
    target_columns = ['ç”³è¾¼å…ˆé›»è©±ç•ªå·', 'ä»£è¡¨è€…éƒµä¾¿ç•ªå·', 'ä»£è¡¨è€…é›»è©±ç•ªå·', 
                     'ä»£è¡¨è€…FAX', 'ä»£è¡¨è€…æºå¸¯ç•ªå·', 'é †ç•ª']
    
    for idx, row in main_data.iterrows():
        error_list = []
        
        for col in target_columns:
            if col in main_data.columns:
                value = normalize_value(row.get(col, ''))
                
                if value:  # ç©ºæ¬„ã§ãªã„å ´åˆã®ã¿ãƒã‚§ãƒƒã‚¯
                    # åŠè§’è‹±æ•°å­—ã€å„ç¨®ãƒã‚¤ãƒ•ãƒ³ã€ãƒ”ãƒªã‚ªãƒ‰ã€ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã€ã‚³ãƒ­ãƒ³ã®ã¿è¨±å¯
                    if not re.match(r'^[a-zA-Z0-9\-â€â€“â€”âˆ’\.\/:]*$', value):
                        error_list.append(f"{col}åˆ—ã«åŠè§’è‹±æ•°å­—ä»¥å¤–ã®æ–‡å­—ãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
        
        errors.append(', '.join(error_list) if error_list else '')
    
    return errors

def validate_email_addresses(main_data):
    """ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã®æ¤œè¨¼
    
    Args:
        main_data (pd.DataFrame): ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿
    
    Returns:
        list: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ
    """
    errors = []
    target_columns = ['Eãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹', 'ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç™ºè¡Œã®ç™»éŒ²ç”¨ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹']
    
    email_pattern = re.compile(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$')
    
    for idx, row in main_data.iterrows():
        error_list = []
        
        for col in target_columns:
            if col in main_data.columns:
                value = normalize_value(row.get(col, ''))
                
                if value and not email_pattern.match(value):
                    error_list.append(f"{col}åˆ—ã®ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãŒç„¡åŠ¹ã§ã™")
        
        errors.append(', '.join(error_list) if error_list else '')
    
    return errors

def validate_required_fields(main_data):
    """å¿…é ˆé …ç›®ã®æ¤œè¨¼
    
    Args:
        main_data (pd.DataFrame): ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿
    
    Returns:
        list: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ
    """
    errors = []
    required_columns = ['ã‚µãƒ¼ã‚¯ãƒ«å', 'ã‚¹ãƒ©ãƒƒã‚°', 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', 'æ´»å‹•ç¨®åˆ¥']
    
    for idx, row in main_data.iterrows():
        error_list = []
        status = normalize_value(row.get('ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦', ''))
        
        # æ–°è¦è¿½åŠ ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if status == 'æ–°è¦è¿½åŠ ':
            errors.append('')
            continue
        
        for col in required_columns:
            if col in main_data.columns:
                value = normalize_value(row.get(col, ''))
                
                if not value:
                    error_list.append(f"{col}åˆ—ãŒç©ºæ¬„ã§ã™")
        
        errors.append(', '.join(error_list) if error_list else '')
    
    return errors

def validate_circle_or_cross(main_data):
    """ãƒãƒ«ãƒãƒ„ã®æ¤œè¨¼
    
    Args:
        main_data (pd.DataFrame): ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿
    
    Returns:
        list: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ
    """
    errors = []
    target_columns = ['å‚åŠ è€…ã®æ¡ä»¶(å¦Šå¨ )', 'å‚åŠ è€…ã®æ¡ä»¶(å¦Šå¨ å¾ŒåŠ)', 'å‚åŠ è€…ã®æ¡ä»¶(0æ­³)', 
                     'å‚åŠ è€…ã®æ¡ä»¶(1æ­³)', 'å‚åŠ è€…ã®æ¡ä»¶(1æ­³å¾ŒåŠ)', 'å‚åŠ è€…ã®æ¡ä»¶(2æ­³)', 
                     'å‚åŠ è€…ã®æ¡ä»¶(2æ­³å¾ŒåŠ)', 'å‚åŠ è€…ã®æ¡ä»¶(3æ­³)', 'å‚åŠ è€…ã®æ¡ä»¶(4æ­³)', 
                     'å‚åŠ è€…ã®æ¡ä»¶(5æ­³)', 'å‚åŠ è€…ã®æ¡ä»¶(6æ­³)', 'å‚åŠ è€…ã®æ¡ä»¶(ã©ãªãŸã§ã‚‚)', 
                     'è¦ä¼šè²»', 'å†Šå­æ²è¼‰å¯', 'HPæ²è¼‰å¯', 'ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿æ²è¼‰å¯']
    
    for idx, row in main_data.iterrows():
        error_list = []
        
        for col in target_columns:
            if col in main_data.columns:
                value = normalize_value(row.get(col, ''))
                
                if value and value not in ['â—‹', '']:
                    error_list.append(f"{col}åˆ—ã«â—‹ã¾ãŸã¯ç©ºæ¬„ä»¥å¤–ã®å€¤ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã™")
        
        errors.append(', '.join(error_list) if error_list else '')
    
    return errors

async def validate_website_urls(main_data):
    """webã‚µã‚¤ãƒˆURLæ¤œè¨¼
    
    Args:
        main_data (pd.DataFrame): ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿
    
    Returns:
        list: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ
    """
    try:
        from validate import is_url_alive
        import aiohttp
    except ImportError as e:
        # validate.pyãŒå­˜åœ¨ã—ãªã„å ´åˆã¯æ¤œè¨¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
        st.warning(f"Webã‚µã‚¤ãƒˆURLæ¤œè¨¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™: {str(e)}")
        return [''] * len(main_data)
    
    errors = []
    target_column = 'Webã‚µã‚¤ãƒˆ'
    
    if target_column not in main_data.columns:
        return [''] * len(main_data)
    
    # ç©ºã§ãªã„URLã®ã¿ã‚’æŠ½å‡º
    urls_to_check = []
    for idx, row in main_data.iterrows():
        raw_value = row.get(target_column, '')
        # ç©ºæ¬„ã¨æ¬ æå€¤ã‚’åŒã˜ã‚‚ã®ã¨ã—ã¦æ‰±ã†
        value = normalize_value(raw_value)
        
        if value:  # ç©ºæ¬„ã§ãªã„å ´åˆã®ã¿ãƒã‚§ãƒƒã‚¯
            # @ã§å§‹ã¾ã‚‹å ´åˆã¯@ã‚’é™¤å»
            if value.startswith('@'):
                value = value[1:]
            urls_to_check.append((idx, value))
        else:
            errors.append('')
    
    if not urls_to_check:
        return errors
    
    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤ºï¼ˆURLæ•°ãŒ2ä»¥ä¸Šã®å ´åˆã®ã¿ï¼‰
    progress_bar = None
    status_text = None
    total_urls = len(urls_to_check)
    
    if total_urls >= 2:
        st.info(f"Webã‚µã‚¤ãƒˆURLæ¤œè¨¼ã‚’é–‹å§‹ã—ã¾ã™ï¼ˆ{total_urls}ä»¶ã®URLã‚’æ¤œè¨¼ï¼‰")
        progress_bar = st.progress(0)
        status_text = st.empty()
        status_text.text(f"Webã‚µã‚¤ãƒˆURLæ¤œè¨¼ä¸­: 0/{total_urls}")
    
    # éåŒæœŸã§URLæ¤œè¨¼ã‚’å®Ÿè¡Œ
    try:
        async with aiohttp.ClientSession() as session:
            for current_index, (idx, url) in enumerate(urls_to_check):
                try:
                    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã®æ›´æ–°
                    if progress_bar is not None:
                        progress = (current_index + 1) / total_urls
                        progress_bar.progress(progress)
                        status_text.text(f"Webã‚µã‚¤ãƒˆURLæ¤œè¨¼ä¸­: {current_index + 1}/{total_urls} - {url[:50]}{'...' if len(url) > 50 else ''}")
                    
                    _, error_msg = await is_url_alive(url, target_column, session)
                    if idx >= len(errors):
                        errors.extend([''] * (idx - len(errors) + 1))
                    errors[idx] = error_msg
                except Exception as e:
                    if idx >= len(errors):
                        errors.extend([''] * (idx - len(errors) + 1))
                    errors[idx] = f"{target_column}åˆ—ã§URLæ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}"
    except Exception as e:
        # aiohttpé–¢é€£ã®ã‚¨ãƒ©ãƒ¼ã®å ´åˆ
        st.warning(f"Webã‚µã‚¤ãƒˆURLæ¤œè¨¼ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯ç©ºã®ã‚¨ãƒ©ãƒ¼ãƒªã‚¹ãƒˆã‚’è¿”ã™
        for idx, _ in urls_to_check:
            if idx >= len(errors):
                errors.extend([''] * (idx - len(errors) + 1))
    finally:
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢
        if progress_bar is not None:
            progress_bar.empty()
        if status_text is not None:
            status_text.empty()
    
    # ä¸è¶³åˆ†ã‚’ç©ºæ–‡å­—ã§åŸ‹ã‚ã‚‹
    while len(errors) < len(main_data):
        errors.append('')
    
    return errors

def validate_facility_location(main_data, facility_data):
    """æ´»å‹•å ´æ‰€ã®æ¤œè¨¼
    
    Args:
        main_data (pd.DataFrame): ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿
        facility_data (pd.DataFrame): æ–½è¨­æƒ…å ±ãƒ‡ãƒ¼ã‚¿
    
    Returns:
        list: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ
    """
    errors = []
    
    if facility_data is None or 'æ–½è¨­å' not in facility_data.columns:
        # æ–½è¨­æƒ…å ±ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        return [''] * len(main_data)
    
    facility_names = set(facility_data['æ–½è¨­å'].astype(str).str.strip())
    
    for idx, row in main_data.iterrows():
        error_list = []
        
        if 'æ´»å‹•å ´æ‰€' in main_data.columns:
            raw_value = row.get('æ´»å‹•å ´æ‰€', '')
            # ç©ºæ¬„ã¨æ¬ æå€¤ã‚’åŒã˜ã‚‚ã®ã¨ã—ã¦æ‰±ã†
            if pd.isna(raw_value):
                value = ''
            else:
                value = str(raw_value).strip()
                if value == 'nan' or value == 'None' or value == '<NA>':
                    value = ''
            
            # ç©ºæ¬„ã§ãªã„å ´åˆã®ã¿ãƒã‚§ãƒƒã‚¯
            if value and value not in facility_names:
                error_list.append("æ´»å‹•å ´æ‰€ãŒæ–½è¨­æƒ…å ±ã«å­˜åœ¨ã—ã¾ã›ã‚“")
        
        errors.append(', '.join(error_list) if error_list else '')
    
    return errors

def validate_status_column(main_data):
    """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ—ã®æ¤œè¨¼
    
    Args:
        main_data (pd.DataFrame): ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿
    
    Returns:
        list: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ
    """
    errors = []
    valid_statuses = ['publish', 'private', '']
    
    for idx, row in main_data.iterrows():
        error_list = []
        
        if 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹' in main_data.columns:
            raw_value = row.get('ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', '')
            # ç©ºæ¬„ã¨æ¬ æå€¤ã‚’åŒã˜ã‚‚ã®ã¨ã—ã¦æ‰±ã†
            if pd.isna(raw_value):
                value = ''
            else:
                value = str(raw_value).strip()
                if value == 'nan' or value == 'None' or value == '<NA>':
                    value = ''
            
            if value not in valid_statuses:
                error_list.append("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ—ã«ç„¡åŠ¹ãªå€¤ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã™")
        
        errors.append(', '.join(error_list) if error_list else '')
    
    return errors

def validate_account_issue_date(main_data):
    """ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç™ºè¡Œå¹´æœˆã®æ¤œè¨¼
    
    Args:
        main_data (pd.DataFrame): ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿
    
    Returns:
        list: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ
    """
    errors = []
    
    # å’Œæš¦ã‹ã‚‰è¥¿æš¦ã¸ã®å¤‰æ›é–¢æ•°ï¼ˆæ¤œè¨¼ç”¨ï¼‰
    def convert_wareki_to_seireki_for_validation(wareki_str):
        if pd.isna(wareki_str):
            return None
        
        # æ–‡å­—åˆ—ã«å¤‰æ›ã—ã¦æ­£è¦åŒ–
        wareki_str = str(wareki_str).strip()
        if not wareki_str or wareki_str in ['nan', 'None', '<NA>']:
            return None
            
        try:
            # ã‚«ãƒ³ãƒã¾ãŸã¯ãƒ”ãƒªã‚ªãƒ‰ã§åˆ†å‰²
            separator = ',' if ',' in wareki_str else '.' if '.' in wareki_str else None
            if separator:
                parts = wareki_str.split(separator)
                if len(parts) == 2:
                    year_part = parts[0].strip()
                    month_part = int(parts[1].strip())
                    
                    # æœˆã®ç¯„å›²ãƒã‚§ãƒƒã‚¯
                    if not (1 <= month_part <= 12):
                        return False  # ç„¡åŠ¹ãªæœˆ
                    
                    if year_part.startswith('R'):
                        # ä»¤å’Œ
                        reiwa_year = int(year_part[1:])
                        # ä»¤å’Œå¹´ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆä»¤å’Œ1å¹´ã€œä»¤å’Œ50å¹´ç¨‹åº¦ã¾ã§ï¼‰
                        if not (1 <= reiwa_year <= 50):
                            return False  # ç„¡åŠ¹ãªä»¤å’Œå¹´
                        seireki_year = 2018 + reiwa_year
                        return seireki_year * 100 + month_part
            return False  # å¤‰æ›ã§ããªã„å½¢å¼
        except:
            return False  # å¤‰æ›ã‚¨ãƒ©ãƒ¼
    
    for idx, row in main_data.iterrows():
        error_list = []
        
        if 'ï½±ï½¶ï½³ï¾ï¾„ç™ºè¡Œå¹´æœˆ' in main_data.columns:
            value = normalize_value(row.get('ï½±ï½¶ï½³ï¾ï¾„ç™ºè¡Œå¹´æœˆ', ''))
            
            # ç©ºæ¬„ã§ãªã„å ´åˆã®ã¿æ¤œè¨¼
            if value:
                conversion_result = convert_wareki_to_seireki_for_validation(value)
                if conversion_result is False:
                    error_list.append("ï½±ï½¶ï½³ï¾ï¾„ç™ºè¡Œå¹´æœˆåˆ—ã«å¤‰æ›ã§ããªã„å€¤ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã™")
        
        errors.append(', '.join(error_list) if error_list else '')
    
    return errors

def validate_weekdays(main_data):
    """æ›œæ—¥ã®æ¤œè¨¼
    
    Args:
        main_data (pd.DataFrame): ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿
    
    Returns:
        list: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ
    """
    errors = []
    target_column = 'æ´»å‹•æ—¥_å–¶æ¥­æ›œæ—¥'
    
    if target_column not in main_data.columns:
        return [''] * len(main_data)
    
    valid_days = {'æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥', 'ç¥'}
    
    for idx, row in main_data.iterrows():
        error_list = []
        
        value = normalize_value(row.get(target_column, ''))
        
        # ç©ºæ¬„ã§ãªã„å ´åˆã®ã¿ãƒã‚§ãƒƒã‚¯
        if value:
            try:
                days = set(value.split(','))  # ã‚«ãƒ³ãƒã§åˆ†å‰²ã—ã¦ã‚»ãƒƒãƒˆã«å¤‰æ›
                if not days.issubset(valid_days):
                    error_list.append("æ´»å‹•æ—¥_å–¶æ¥­æ›œæ—¥åˆ—ã¯ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§å…¥åŠ›ã—ã¦ãã ã•ã„")
            except AttributeError:
                error_list.append("æ´»å‹•æ—¥_å–¶æ¥­æ›œæ—¥åˆ—ã¯ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§å…¥åŠ›ã—ã¦ãã ã•ã„")
        
        errors.append(', '.join(error_list) if error_list else '')
    
    return errors

def validate_business_hours(main_data):
    """æ™‚é–“ã®æ¤œè¨¼
    
    Args:
        main_data (pd.DataFrame): ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿
    
    Returns:
        list: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ
    """
    errors = []
    start_column = 'æ´»å‹•æ—¥_é–‹å§‹æ™‚é–“'
    end_column = 'æ´»å‹•æ—¥_çµ‚äº†æ™‚é–“'
    
    # åˆ—ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ç©ºã®ã‚¨ãƒ©ãƒ¼ãƒªã‚¹ãƒˆã‚’è¿”ã™
    if start_column not in main_data.columns or end_column not in main_data.columns:
        return [''] * len(main_data)
    
    def is_valid_time_format(time_str):
        """æ™‚é–“å½¢å¼ãŒæ­£ã—ã„ã‹ãƒã‚§ãƒƒã‚¯"""
        if not time_str:
            return False
        try:
            # HH:MM ã¾ãŸã¯ HH:MM:SS å½¢å¼ã‚’ãƒã‚§ãƒƒã‚¯
            if ':' not in time_str:
                return False
            
            parts = time_str.split(':')
            if len(parts) == 2:  # HH:MM
                hours, minutes = map(int, parts)
                return 0 <= hours <= 23 and 0 <= minutes <= 59
            elif len(parts) == 3:  # HH:MM:SS
                hours, minutes, seconds = map(int, parts)
                return 0 <= hours <= 23 and 0 <= minutes <= 59 and 0 <= seconds <= 59
            else:
                return False
        except (ValueError, TypeError):
            return False
    
    def time_to_minutes(time_str):
        """æ™‚é–“æ–‡å­—åˆ—ã‚’åˆ†ã«å¤‰æ›ï¼ˆæ¯”è¼ƒç”¨ï¼‰"""
        try:
            parts = time_str.split(':')
            hours = int(parts[0])
            minutes = int(parts[1])
            return hours * 60 + minutes
        except (ValueError, IndexError):
            return None
    
    for idx, row in main_data.iterrows():
        error_list = []
        
        start_value = normalize_value(row.get(start_column, ''))
        end_value = normalize_value(row.get(end_column, ''))
        
        # ä¸¡æ–¹ç©ºæ¬„ã®å ´åˆã¯æ¤œè¨¼ã—ãªã„
        if not start_value and not end_value:
            errors.append('')
            continue
        
        # é–‹å§‹æ™‚é–“ã®å½¢å¼ãƒã‚§ãƒƒã‚¯
        start_valid = is_valid_time_format(start_value) if start_value else True
        end_valid = is_valid_time_format(end_value) if end_value else True
        
        if start_value and not start_valid:
            if end_value and not end_valid:
                error_list.append("é–‹å§‹+çµ‚äº†æ™‚é–“ã®å½¢å¼ãŒé•ã„ã¾ã™")
            else:
                error_list.append("é–‹å§‹æ™‚é–“ã®å½¢å¼ãŒé•ã„ã¾ã™")
        elif end_value and not end_valid:
            error_list.append("çµ‚äº†æ™‚é–“ã®å½¢å¼ãŒé•ã„ã¾ã™")
        elif start_value and end_value and start_valid and end_valid:
            # é–‹å§‹æ™‚é–“ã¨çµ‚äº†æ™‚é–“ã®è«–ç†ãƒã‚§ãƒƒã‚¯
            start_minutes = time_to_minutes(start_value)
            end_minutes = time_to_minutes(end_value)
            
            if start_minutes is not None and end_minutes is not None:
                if start_minutes >= end_minutes:
                    error_list.append("é–‹å§‹æ™‚é–“ã¨çµ‚äº†æ™‚é–“ãŒåŒã˜ã¾ãŸã¯é€†è»¢ã—ã¦ã„ã¾ã™")
        
        errors.append(', '.join(error_list) if error_list else '')
    
    return errors

def perform_data_validation(main_data, original_data, facility_data=None, validation_options=None):
    """ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã®å®Ÿè¡Œ
    
    Args:
        main_data (pd.DataFrame): ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿
        original_data (pd.DataFrame): å·®åˆ†æ¤œå‡ºç”¨ãƒ‡ãƒ¼ã‚¿
        facility_data (pd.DataFrame, optional): æ–½è¨­æƒ…å ±ãƒ‡ãƒ¼ã‚¿
        validation_options (dict, optional): å®Ÿè¡Œã™ã‚‹æ¤œè¨¼é …ç›®ã®é¸æŠ
    
    Returns:
        pd.DataFrame: ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’å«ã‚€ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿
    """
    # ã‚¨ãƒ©ãƒ¼åˆ—ã‚’åˆæœŸåŒ–
    main_data_with_errors = main_data.copy()
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯å…¨ã¦ã®æ¤œè¨¼ã‚’å®Ÿè¡Œ
    if validation_options is None:
        validation_options = {
            'modification_status': True,
            'empty_status': True,
            'machine_dependent': True,
            'cell_breaks': True,
            'prohibited_changes': True,
            'consecutive_spaces': True,
            'alphanumeric': True,
            'email': True,
            'required_fields': True,
            'circle_cross': True,
            'facility_location': True,
            'status_column': True,
            'website_urls': True,
            'account_issue_date': True,
            'weekdays': True,
            'business_hours': True
        }
    
    # å„æ¤œè¨¼ã‚’å®Ÿè¡Œ
    validation_functions = [
        ('modification_status', 'ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', lambda: validate_modification_status(main_data, original_data)),
        ('empty_status', 'ç©ºæ¬„ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', lambda: validate_empty_status(main_data, original_data)),
        ('machine_dependent', 'æ©Ÿç¨®ä¾å­˜æ–‡å­—', lambda: validate_machine_dependent_characters(main_data)),
        ('cell_breaks', 'ã‚»ãƒ«å†…æ”¹è¡Œ', lambda: validate_cell_line_breaks(main_data)),
        ('prohibited_changes', 'å¤‰æ›´ç¦æ­¢åˆ—', lambda: validate_prohibited_changes(main_data, original_data)),
        ('consecutive_spaces', 'é€£ç¶šã—ãŸç©ºç™½', lambda: validate_consecutive_spaces(main_data)),
        ('alphanumeric', 'åŠè§’è‹±æ•°', lambda: validate_alphanumeric(main_data)),
        ('email', 'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹', lambda: validate_email_addresses(main_data)),
        ('required_fields', 'å¿…é ˆé …ç›®', lambda: validate_required_fields(main_data)),
        ('circle_cross', 'ãƒãƒ«ãƒãƒ„', lambda: validate_circle_or_cross(main_data)),
        ('facility_location', 'æ´»å‹•å ´æ‰€', lambda: validate_facility_location(main_data, facility_data)),
        ('status_column', 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', lambda: validate_status_column(main_data)),
        ('account_issue_date', 'ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç™ºè¡Œå¹´æœˆ', lambda: validate_account_issue_date(main_data)),
        ('weekdays', 'æ›œæ—¥', lambda: validate_weekdays(main_data)),
        ('business_hours', 'æ™‚é–“', lambda: validate_business_hours(main_data))
    ]
    
    # éåŒæœŸæ¤œè¨¼ï¼ˆwebã‚µã‚¤ãƒˆURLæ¤œè¨¼ï¼‰
    async_validation_functions = [
        ('website_urls', 'webã‚µã‚¤ãƒˆURL', lambda: validate_website_urls(main_data))
    ]
    
    all_errors = []
    executed_validations = []
    
    # åŒæœŸæ¤œè¨¼ã‚’å®Ÿè¡Œ
    for validation_key, validation_name, validation_func in validation_functions:
        if validation_options.get(validation_key, False):
            try:
                errors = validation_func()
                all_errors.append(errors)
                executed_validations.append(validation_name)
            except Exception as e:
                st.error(f"{validation_name}ã®æ¤œè¨¼ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                all_errors.append([''] * len(main_data))
                executed_validations.append(f"{validation_name}ï¼ˆã‚¨ãƒ©ãƒ¼ï¼‰")
    
    # éåŒæœŸæ¤œè¨¼ã‚’å®Ÿè¡Œ
    import asyncio
    for validation_key, validation_name, validation_func in async_validation_functions:
        if validation_options.get(validation_key, False):
            try:
                errors = asyncio.run(validation_func())
                all_errors.append(errors)
                executed_validations.append(validation_name)
            except Exception as e:
                st.error(f"{validation_name}ã®æ¤œè¨¼ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                all_errors.append([''] * len(main_data))
                executed_validations.append(f"{validation_name}ï¼ˆã‚¨ãƒ©ãƒ¼ï¼‰")
    
    # å®Ÿè¡Œã•ã‚ŒãŸæ¤œè¨¼é …ç›®ã‚’è¡¨ç¤º
    if executed_validations:
        st.info(f"å®Ÿè¡Œã•ã‚ŒãŸæ¤œè¨¼é …ç›®: {', '.join(executed_validations)}")
    else:
        st.warning("æ¤œè¨¼é …ç›®ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        main_data_with_errors['ã‚¨ãƒ©ãƒ¼'] = [''] * len(main_data)
        return main_data_with_errors
    
    # å…¨ã¦ã®ã‚¨ãƒ©ãƒ¼ã‚’çµ±åˆ
    combined_errors = []
    for i in range(len(main_data)):
        row_errors = []
        for error_list in all_errors:
            if i < len(error_list) and error_list[i]:
                row_errors.append(error_list[i])
        combined_errors.append(', '.join(row_errors))
    
    main_data_with_errors['ã‚¨ãƒ©ãƒ¼'] = combined_errors
    
    return main_data_with_errors

def validate_import_excel_file(excel_file, skip_rows_count=2):
    """ã‚¤ãƒ³ãƒãƒ¼ãƒˆç”¨Excelãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼ã¨èª­ã¿è¾¼ã¿ã‚’è¡Œã†
    
    Args:
        excel_file: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸExcelãƒ•ã‚¡ã‚¤ãƒ«
        skip_rows_count: ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹è¡Œæ•°
    
    Returns:
        tuple: (ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿, å·®åˆ†æ¤œå‡ºç”¨ãƒ‡ãƒ¼ã‚¿)
    """
    try:
        # Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã‚·ãƒ¼ãƒˆæƒ…å ±ã‚’å–å¾—
        wb = pd.ExcelFile(excel_file)
        sheet_names = wb.sheet_names
        
        # ã‚·ãƒ¼ãƒˆæ•°ã®æ¤œè¨¼
        if len(sheet_names) > 2:
            raise ValueError("ã‚·ãƒ¼ãƒˆæ•°ãŒ2ã‚ˆã‚Šå¤šã„ãŸã‚ã€ã©ã®ã‚·ãƒ¼ãƒˆã‚’ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã«ã™ã‚‹ã‹ãŒç‰¹å®šã§ãã¾ã›ã‚“")
        
        if len(sheet_names) < 2:
            raise ValueError("originalã‚·ãƒ¼ãƒˆã¨åˆ¥ã®ã‚·ãƒ¼ãƒˆãŒå¿…è¦ã§ã™ãŒã€ã‚·ãƒ¼ãƒˆæ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
        
        # originalã‚·ãƒ¼ãƒˆã¨åˆ¥ã‚·ãƒ¼ãƒˆã‚’ç‰¹å®š
        original_sheet = None
        main_sheet = None
        
        for sheet_name in sheet_names:
            if sheet_name.lower() == 'original':
                original_sheet = sheet_name
            else:
                main_sheet = sheet_name
        
        if original_sheet is None:
            raise ValueError("'original'ã¨ã„ã†åå‰ã®ã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ï¼ˆæŒ‡å®šã•ã‚ŒãŸè¡Œæ•°ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰
        main_data = pd.read_excel(excel_file, sheet_name=main_sheet, skiprows=list(range(1, skip_rows_count + 1)))
        
        # å·®åˆ†æ¤œå‡ºç”¨ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ï¼ˆæŒ‡å®šã•ã‚ŒãŸè¡Œæ•°ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰
        original_data = pd.read_excel(excel_file, sheet_name=original_sheet, skiprows=list(range(1, skip_rows_count + 1)))
        
        # åŸºæœ¬çš„ãªæ¤œè¨¼
        if main_data.empty:
            raise ValueError("ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
        if original_data.empty:
            raise ValueError("å·®åˆ†æ¤œå‡ºç”¨ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
            
        if len(main_data.columns) == 0:
            raise ValueError("ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã«åˆ—ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
        if len(original_data.columns) == 0:
            raise ValueError("å·®åˆ†æ¤œå‡ºç”¨ãƒ‡ãƒ¼ã‚¿ã«åˆ—ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
        
        return main_data, original_data
        
    except Exception as e:
        raise ValueError(f"Excelãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

def show_import_data_page():
    """ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆãƒšãƒ¼ã‚¸ã®è¡¨ç¤º"""
    log_session_state_change("page_loaded", {'page': 'import_data'})
    
    st.header("ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ")
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
    show_session_state_debug()
    
    # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰æ™‚ã®ã¿è¡¨ç¤ºã•ã‚Œã‚‹æƒ…å ±
    if st.session_state.debug_mode:
        st.write("### ãƒ‡ãƒãƒƒã‚°æƒ…å ±")
        st.write("ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ãŒæœ‰åŠ¹ã§ã™")
    
    st.write("### ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    
    # ä¿®æ­£æ¸ˆã¿Excelãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    excel_file = st.file_uploader("ä¿®æ­£æ¸ˆã¿Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„", type=['xlsx'], key="import_excel")
    
    # ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹è¡Œæ•°ã®æŒ‡å®š
    skip_rows = st.number_input("ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹è¡Œæ•°", min_value=0, max_value=10, value=2, 
                               help="ãƒ˜ãƒƒãƒ€ãƒ¼ä»¥å¤–ã®ä¸Šã‹ã‚‰ä½•è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã‹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
    
    main_data = None
    original_data = None
    
    if excel_file:
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã®ã¿ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
            if check_file_changed(excel_file, 'excel'):
                reset_import_session_state()
            
            # Excelãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼ã¨èª­ã¿è¾¼ã¿
            main_data, original_data = validate_import_excel_file(excel_file, skip_rows)
            
            st.success("Excelãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£å¸¸ã«èª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸ")
            
            col1, col2 = st.columns(2)
            with col1:
                with st.expander("ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã™ã‚‹"):
                    st.dataframe(main_data, use_container_width=True)
                    st.info(f"è¡Œæ•°: {len(main_data)}, åˆ—æ•°: {len(main_data.columns)}")
            
            with col2:
                with st.expander("å·®åˆ†æ¤œå‡ºç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã™ã‚‹"):
                    st.dataframe(original_data, use_container_width=True)
                    st.info(f"è¡Œæ•°: {len(original_data)}, åˆ—æ•°: {len(original_data.columns)}")
                    
        except ValueError as e:
            st.error(f"Excelãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ©ãƒ¼: {str(e)}")
        except Exception as e:
            st.error(f"Excelãƒ•ã‚¡ã‚¤ãƒ«ã®äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    # æ–½è¨­æƒ…å ±CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ç”¨ï¼‰
    facility_csv_file = st.file_uploader("æ–½è¨­æƒ…å ±CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„", type=['csv'], key="import_facility")
    facility_data = None
    
    if facility_csv_file:
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã®ã¿ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
            if check_file_changed(facility_csv_file, 'facility'):
                reset_import_session_state()
            
            # æ–½è¨­æƒ…å ±CSVãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼ã¨èª­ã¿è¾¼ã¿
            facility_data, facility_encoding, facility_debug_info = validate_csv_file(facility_csv_file)
            
            st.success(f"æ–½è¨­æƒ…å ±CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£å¸¸ã«èª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°: {facility_encoding}ï¼‰")
            with st.expander("æ–½è¨­æƒ…å ±ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã™ã‚‹"):
                st.dataframe(facility_data, use_container_width=True)
                
            # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰æ™‚ã«è©³ç´°æƒ…å ±ã‚’è¡¨ç¤º
            if st.session_state.get('debug_mode', False):
                with st.expander("ğŸ” æ–½è¨­æƒ…å ±CSVèª­ã¿è¾¼ã¿è©³ç´°"):
                    st.write("**ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¤œå‡ºãƒ­ã‚°:**")
                    for info in facility_debug_info:
                        st.text(info)
        except ValueError as e:
            st.error(f"æ–½è¨­æƒ…å ±CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ©ãƒ¼: {str(e)}")
        except Exception as e:
            st.error(f"æ–½è¨­æƒ…å ±CSVãƒ•ã‚¡ã‚¤ãƒ«ã®äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆç”¨ï¼‰
    user_csv_file = st.file_uploader("ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„", type=['csv'], key="import_user")
    user_data = None
    
    if user_csv_file:
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã®ã¿ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
            if check_file_changed(user_csv_file, 'user'):
                reset_import_session_state()
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿CSVãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼ã¨èª­ã¿è¾¼ã¿
            user_data, user_encoding, user_debug_info = validate_csv_file(user_csv_file)
            
            st.success(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£å¸¸ã«èª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°: {user_encoding}ï¼‰")
            with st.expander("ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã™ã‚‹"):
                st.dataframe(user_data, use_container_width=True)
                
            # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰æ™‚ã«è©³ç´°æƒ…å ±ã‚’è¡¨ç¤º
            if st.session_state.get('debug_mode', False):
                with st.expander("ğŸ” ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿CSVèª­ã¿è¾¼ã¿è©³ç´°"):
                    st.write("**ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¤œå‡ºãƒ­ã‚°:**")
                    for info in user_debug_info:
                        st.text(info)
        except ValueError as e:
            st.error(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ©ãƒ¼: {str(e)}")
        except Exception as e:
            st.error(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿CSVãƒ•ã‚¡ã‚¤ãƒ«ã®äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    # å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ãŒæƒã£ã¦ã„ã‚‹ã‹ç¢ºèª
    all_data_ready = (
        main_data is not None and
        original_data is not None and
        facility_data is not None and
        user_data is not None
    )
    
    if all_data_ready:
        st.success("å…¨ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£å¸¸ã«èª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚’é–‹å§‹ã§ãã¾ã™ã€‚")
        
                # è‡ªæ²»ä½“åã®å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
        municipality = st.text_input("è‡ªæ²»ä½“å", value="åŒ—ä¹å·å¸‚", help="ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ç”¨ã•ã‚Œã‚‹è‡ªæ²»ä½“åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", key="import_municipality")
        
        # æ¤œè¨¼é …ç›®ã®é¸æŠ
        st.write("### å®Ÿæ–½ã™ã‚‹æ¤œè¨¼é …ç›®ã‚’é¸æŠã—ã¦ãã ã•ã„")
        
        # æ¤œè¨¼é …ç›®ã®å®šç¾©ï¼ˆã‚­ãƒ¼: (è¡¨ç¤ºå, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤, ãƒ˜ãƒ«ãƒ—ãƒ†ã‚­ã‚¹ãƒˆ)ï¼‰
        validation_items = {
            'modification_status': ('ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', True, 'ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦åˆ—ã®å€¤ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚ä¿®æ­£æ™‚ã®å¤‰æ›´æœ‰ç„¡ã€æ–°è¦è¿½åŠ æ™‚ã®ã‚¹ãƒ©ãƒƒã‚°ç©ºæ¬„ã€æ²è¼‰é †å¤‰æ›´ã®å¦¥å½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚'),
            'empty_status': ('ç©ºæ¬„ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', True, 'ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦åˆ—ãŒç©ºæ¬„ã®å ´åˆã«ã€å®Ÿéš›ã«ãƒ‡ãƒ¼ã‚¿ãŒå¤‰æ›´ã•ã‚Œã¦ã„ãªã„ã‹ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚'),
            'machine_dependent': ('æ©Ÿç¨®ä¾å­˜æ–‡å­—', True, 'ã‚µãƒ¼ã‚¯ãƒ«åã€æ¦‚è¦ã€æ´»å‹•å ´æ‰€ãªã©ã®æ–‡å­—åˆ—é …ç›®ã«æ©Ÿç¨®ä¾å­˜æ–‡å­—ï¼ˆâ‘ â‘¡â‘¢ãªã©ï¼‰ãŒå«ã¾ã‚Œã¦ã„ãªã„ã‹ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚'),
            'cell_breaks': ('ã‚»ãƒ«å†…æ”¹è¡Œ', True, 'ã‚»ãƒ«å†…ã«æ”¹è¡Œæ–‡å­—ï¼ˆ\\nã€\\rï¼‰ãŒå«ã¾ã‚Œã¦ã„ãªã„ã‹ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤ºå´©ã‚Œã‚’é˜²ãã¾ã™ã€‚'),
            'prohibited_changes': ('å¤‰æ›´ç¦æ­¢åˆ—', True, 'ã‚¹ãƒ©ãƒƒã‚°ã€ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã€å‚åŠ è€…ã®æ¡ä»¶ï¼ˆå¾ŒåŠï¼‰ã€ç”³è¾¼æ–¹æ³•å‚™è€ƒãªã©ã®å¤‰æ›´ç¦æ­¢åˆ—ãŒå¤‰æ›´ã•ã‚Œã¦ã„ãªã„ã‹ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚'),
            'consecutive_spaces': ('é€£ç¶šã—ãŸç©ºç™½', True, 'æ–‡å­—åˆ—é …ç›®ã«3ã¤ä»¥ä¸Šã®é€£ç¶šã—ãŸç©ºç™½ãŒå«ã¾ã‚Œã¦ã„ãªã„ã‹ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚'),
            'alphanumeric': ('åŠè§’è‹±æ•°', True, 'é›»è©±ç•ªå·ã€éƒµä¾¿ç•ªå·ã€é †ç•ªãªã©ã®é …ç›®ãŒåŠè§’è‹±æ•°å­—ã§å…¥åŠ›ã•ã‚Œã¦ã„ã‚‹ã‹ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚'),
            'email': ('ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹', True, 'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹é …ç›®ãŒæ­£ã—ã„å½¢å¼ã§å…¥åŠ›ã•ã‚Œã¦ã„ã‚‹ã‹ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚'),
            'required_fields': ('å¿…é ˆé …ç›®', True, 'ã‚µãƒ¼ã‚¯ãƒ«åã€ã‚¹ãƒ©ãƒƒã‚°ã€ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã€æ´»å‹•ç¨®åˆ¥ãªã©ã®å¿…é ˆé …ç›®ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã‚‹ã‹ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚'),
            'circle_cross': ('ãƒãƒ«ãƒãƒ„', True, 'å‚åŠ è€…ã®æ¡ä»¶ã€è¦ä¼šè²»ã€æ²è¼‰å¯èƒ½æ€§ãªã©ã®é …ç›®ãŒâ—‹ã¾ãŸã¯ç©ºæ¬„ã§å…¥åŠ›ã•ã‚Œã¦ã„ã‚‹ã‹ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚'),
            'facility_location': ('æ´»å‹•å ´æ‰€', True, 'æ´»å‹•å ´æ‰€ã«å…¥åŠ›ã•ã‚ŒãŸæ–½è¨­åãŒæ–½è¨­æƒ…å ±ãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã™ã‚‹ã‹ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚'),
            'status_column': ('ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', True, 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ—ã®å€¤ãŒpublishã€privateã€ã¾ãŸã¯ç©ºæ¬„ã®ã„ãšã‚Œã‹ã§ã‚ã‚‹ã‹ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚'),
            'website_urls': ('webã‚µã‚¤ãƒˆURL', True, 'Webã‚µã‚¤ãƒˆURLãŒæœ‰åŠ¹ã§ã€å®Ÿéš›ã«ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã‹ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚ï¼ˆæ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ï¼‰'),
            'weekdays': ('æ›œæ—¥', True, 'æ´»å‹•æ—¥_å–¶æ¥­æ›œæ—¥åˆ—ãŒã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®æ­£ã—ã„æ›œæ—¥å½¢å¼ï¼ˆæœˆ,ç«,æ°´ãªã©ï¼‰ã§å…¥åŠ›ã•ã‚Œã¦ã„ã‚‹ã‹ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚'),
            'business_hours': ('æ™‚é–“', True, 'æ´»å‹•æ—¥_é–‹å§‹æ™‚é–“ã¨æ´»å‹•æ—¥_çµ‚äº†æ™‚é–“ãŒHH:MMå½¢å¼ã§å…¥åŠ›ã•ã‚Œã€é–‹å§‹æ™‚é–“ãŒçµ‚äº†æ™‚é–“ã‚ˆã‚Šå‰ã§ã‚ã‚‹ã“ã¨ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚')
        }
        
        # ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã‚’3åˆ—ã«å‡ç­‰é…ç½®
        validation_states = {}
        items_list = list(validation_items.items())
        columns = st.columns(3)
        
        # é …ç›®ã‚’3åˆ—ã«åˆ†æ•£é…ç½®
        for i, (key, (display_name, default_value, help_text)) in enumerate(items_list):
            col_index = i % 3  # é †ç•ªã«åˆ—ã‚’å¾ªç’°
            with columns[col_index]:
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«å€¤ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ã€ãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨
                checkbox_value = st.session_state.get(f"check_{key}", default_value)
                validation_states[key] = st.checkbox(
                    display_name,
                    value=checkbox_value,
                    help=help_text,
                    key=f"check_{key}"
                )
        
        # å…¨é¸æŠãƒ»å…¨è§£é™¤ãƒœã‚¿ãƒ³ç”¨ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
        def select_all_callback():
            for key in validation_items.keys():
                st.session_state[f"check_{key}"] = True
        
        def deselect_all_callback():
            for key in validation_items.keys():
                st.session_state[f"check_{key}"] = False
        
        col_btn1, col_btn2, col_btn3 = st.columns([1, 1, 4])
        with col_btn1:
            st.button("å…¨é¸æŠ", key="select_all", on_click=select_all_callback)
        
        with col_btn2:
            st.button("å…¨è§£é™¤", key="deselect_all", on_click=deselect_all_callback)
        
        if st.button("ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼é–‹å§‹", key="start_validation"):
            try:
                with st.spinner("ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚’å®Ÿè¡Œä¸­..."):
                    # é¸æŠã•ã‚ŒãŸæ¤œè¨¼é …ç›®ã‚’å–å¾—
                    validation_options = {key: validation_states[key] for key in validation_items.keys()}
                    
                    # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚’å®Ÿè¡Œ
                    validated_data = perform_data_validation(main_data, original_data, facility_data, validation_options)
                    
                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
                    st.session_state.validated_data = validated_data
                    st.session_state.validation_completed = True
                    log_session_state_change("validation_completed", {
                        'data_rows': len(validated_data),
                        'selected_validations': list(validation_options.keys())
                    })
                    
                    # ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹è¡Œã®æ•°ã‚’è¨ˆç®—
                    error_rows = validated_data[validated_data['ã‚¨ãƒ©ãƒ¼'] != '']
                    error_count = len(error_rows)
                    
            except Exception as e:
                st.error(f"ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                if st.session_state.get('debug_mode', False):
                    st.exception(e)
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«åŸºã¥ã„ã¦æ¤œè¨¼çµæœã‚’è¡¨ç¤º
        if st.session_state.validation_completed and st.session_state.validated_data is not None:
            validated_data = st.session_state.validated_data
            
            # ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹è¡Œã®æ•°ã‚’è¨ˆç®—
            error_rows = validated_data[validated_data['ã‚¨ãƒ©ãƒ¼'] != '']
            error_count = len(error_rows)
            
            if error_count > 0:
                st.error(f"ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãŒå®Œäº†ã—ã¾ã—ãŸã€‚{error_count}ä»¶ã®ã‚¨ãƒ©ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")
                
                # ã‚¨ãƒ©ãƒ¼è©³ç´°ã®è¡¨ç¤º
                with st.expander(f"ã‚¨ãƒ©ãƒ¼è©³ç´°ã‚’ç¢ºèªã™ã‚‹ ({error_count}ä»¶)"):
                    st.dataframe(error_rows[['ã‚µãƒ¼ã‚¯ãƒ«å', 'ã‚¹ãƒ©ãƒƒã‚°', 'ã‚¨ãƒ©ãƒ¼']], use_container_width=True)
                
                # å…¨ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚¨ãƒ©ãƒ¼åˆ—ä»˜ãï¼‰ã®è¡¨ç¤º
                with st.expander("æ¤œè¨¼çµæœã‚’ç¢ºèªã™ã‚‹ï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿ï¼‰"):
                    st.dataframe(validated_data, use_container_width=True)
                
                # ã‚¨ãƒ©ãƒ¼ä»˜ããƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                current_date = datetime.datetime.now().strftime("%Y%m%d")
                error_file_name = f"{municipality}_ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼çµæœ_{current_date}.xlsx"
                
                # Excelãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦å‡ºåŠ›
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    validated_data.to_excel(writer, sheet_name='æ¤œè¨¼çµæœ', index=False)
                    error_rows.to_excel(writer, sheet_name='ã‚¨ãƒ©ãƒ¼ä¸€è¦§', index=False)
                
                output.seek(0)
                st.download_button(
                    label="æ¤œè¨¼çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=output,
                    file_name=error_file_name,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
                
            else:
                st.success("ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ã‚¨ãƒ©ãƒ¼ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                
                # ãƒãƒ«ãƒ¼ãƒ³ã¯ä¸€åº¦ã ã‘è¡¨ç¤º
                if not st.session_state.get('balloons_shown', False):
                    st.balloons()
                    st.session_state.balloons_shown = True
                
                # å…¨ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º
                with st.expander("æ¤œè¨¼çµæœã‚’ç¢ºèªã™ã‚‹"):
                    st.dataframe(validated_data, use_container_width=True)
                
                # ãƒ‡ãƒ¼ã‚¿æ•´å½¢ã¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
                st.write("### ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ")
                
                # ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆç”¨ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
                def create_import_data_callback():
                    try:
                        log_session_state_change("import_data_creation_started", {
                            'municipality': municipality
                        })
                        
                        # ãƒ‡ãƒ¼ã‚¿ã‚’æ•´å½¢
                        formatted_data = format_for_import(main_data, original_data)
                        log_session_state_change("data_formatted", {
                            'formatted_rows': len(formatted_data)
                        })
                        
                        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
                        import_files = create_import_files(formatted_data, original_data, user_data, municipality, main_data)
                        log_session_state_change("import_files_created", {
                            'file_count': len(import_files) if import_files else 0,
                            'filenames': list(import_files.keys()) if import_files else []
                        })
                        
                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
                        st.session_state.import_files = import_files
                        st.session_state.formatted_data = formatted_data
                        st.session_state.import_data_created = True
                        log_session_state_change("import_data_creation_completed", {
                            'success': True
                        })
                        
                    except Exception as e:
                        log_session_state_change("import_data_creation_error", {
                            'error': str(e)
                        })
                        st.error(f"ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                        if st.session_state.get('debug_mode', False):
                            st.exception(e)
                
                # ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆãƒœã‚¿ãƒ³
                st.button("ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆé–‹å§‹", key="start_import_creation", on_click=create_import_data_callback)
                
                # ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ãŒä½œæˆæ¸ˆã¿ã®å ´åˆã€çµæœã‚’è¡¨ç¤º
                if st.session_state.import_data_created and st.session_state.import_files is not None:
                    import_files = st.session_state.import_files
                    formatted_data = st.session_state.formatted_data
                    
                    if import_files:
                        st.success(f"{len(import_files)}å€‹ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã¾ã—ãŸã€‚")
                        
                        # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç™ºè¡Œå¹´æœˆã®è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒã‚ã‚‹å ´åˆã¯è¡¨ç¤º
                        if 'account_date_warning' in st.session_state:
                            st.warning(st.session_state.account_date_warning)
                            # è­¦å‘Šã‚’è¡¨ç¤ºã—ãŸã‚‰ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰å‰Šé™¤ï¼ˆé‡è¤‡è¡¨ç¤ºã‚’é˜²ãï¼‰
                            del st.session_state.account_date_warning
                        
                        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆã®è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒã‚ã‚‹å ´åˆã¯è¡¨ç¤º
                        if 'user_creation_warning' in st.session_state:
                            st.warning(st.session_state.user_creation_warning)
                            # è­¦å‘Šã‚’è¡¨ç¤ºã—ãŸã‚‰ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰å‰Šé™¤ï¼ˆé‡è¤‡è¡¨ç¤ºã‚’é˜²ãï¼‰
                            del st.session_state.user_creation_warning
                        
                        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¿®æ­£ã®å·®åˆ†è¡¨ç¤º
                        if 'user_modification_details' in st.session_state:
                            st.info("### ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã®ä¿®æ­£å†…å®¹")
                            modification_df = pd.DataFrame(st.session_state.user_modification_details)
                            st.dataframe(modification_df, use_container_width=True, hide_index=True)
                            st.caption("ä¸Šè¨˜ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ãŒä¿®æ­£ã•ã‚Œã¾ã™ã€‚å†…å®¹ã‚’ç¢ºèªã—ã¦ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
                            # è¡¨ç¤ºã—ãŸã‚‰ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰å‰Šé™¤ï¼ˆé‡è¤‡è¡¨ç¤ºã‚’é˜²ãï¼‰
                            del st.session_state.user_modification_details
                        
                        # å‰Šé™¤å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º
                        deletion_data = formatted_data[formatted_data['ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦'] == 'å‰Šé™¤']
                        if not deletion_data.empty:
                            st.warning("### ğŸ—‘ï¸ å‰Šé™¤å¯¾è±¡ãƒ‡ãƒ¼ã‚¿")
                            st.write("ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦ã¯ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§æ¶ˆãˆãªã„ãŸã‚ã€ç®¡ç†ç”»é¢ã‹ã‚‰**ãƒœãƒŸç®±ãƒã‚¤**ã‚’å¿˜ã‚Œãšã«")
                            
                            # å‰Šé™¤å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤ºï¼ˆé‡è¦ãªåˆ—ã®ã¿ï¼‰
                            display_columns = ['ã‚µãƒ¼ã‚¯ãƒ«å', 'ã‚¹ãƒ©ãƒƒã‚°', 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', 'ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦']
                            available_columns = [col for col in display_columns if col in deletion_data.columns]
                            
                            st.dataframe(
                                deletion_data[available_columns], 
                                use_container_width=True, 
                                hide_index=True
                            )
                            st.caption(f"ğŸ’¡ å‰Šé™¤å¯¾è±¡: {len(deletion_data)}ä»¶ã®ã‚µãƒ¼ã‚¯ãƒ«ãƒ‡ãƒ¼ã‚¿")
                            st.caption("âš ï¸ ã“ã‚Œã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã¯ã‚¤ãƒ³ãƒãƒ¼ãƒˆå¾Œã«ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãŒã€Œprivateã€ã«ãªã‚Šã¾ã™ãŒã€å®Œå…¨ã«å‰Šé™¤ã•ã‚Œã‚‹ã‚ã‘ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
                            st.caption("ğŸ“‹ ç®¡ç†ç”»é¢ã‹ã‚‰æ‰‹å‹•ã§ã‚´ãƒŸç®±ã«ç§»å‹•ã™ã‚‹ä½œæ¥­ãŒå¿…è¦ã§ã™ã€‚")
                        
                        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆç”¨CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®è¦‹å‡ºã—
                        st.markdown("---")
                        st.subheader("ğŸ“¥ ã‚¤ãƒ³ãƒãƒ¼ãƒˆç”¨CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
                        st.write("ä½œæˆã•ã‚ŒãŸã‚¤ãƒ³ãƒãƒ¼ãƒˆç”¨CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
                        
                        # å„ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
                        for filename, data in import_files.items():
                            # ä¿®æ­£CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯ç‰¹åˆ¥ãªå‡¦ç†
                            if isinstance(data, dict) and 'display_data' in data and 'download_data' in data:
                                # ä¿®æ­£CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
                                display_data = data['display_data']  # è¡¨ç¤ºç”¨ï¼ˆä¿®æ­£å¯¾è±¡åˆ—å«ã‚€ï¼‰
                                download_data = data['download_data']  # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ï¼ˆä¿®æ­£å¯¾è±¡åˆ—é™¤å¤–ï¼‰
                                
                                # CSVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦å‡ºåŠ›ï¼ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰
                                csv_output = io.StringIO()
                                download_data.to_csv(csv_output, index=False, encoding='utf-8-sig')
                                csv_data = csv_output.getvalue().encode('utf-8-sig')
                                
                                st.download_button(
                                    label=f"ğŸ“ {filename}",
                                    data=csv_data,
                                    file_name=filename,
                                    mime="text/csv",
                                    key=f"download_{filename}"
                                )
                                
                                # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆè¡¨ç¤ºç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰
                                with st.expander(f"ğŸ“‹ {filename} ã®å†…å®¹ã‚’ç¢ºèª"):
                                    st.dataframe(display_data, use_container_width=True)
                                    st.info(f"è¡Œæ•°: {len(display_data)}, åˆ—æ•°: {len(display_data.columns)}")
                                    st.caption("ğŸ’¡ ã€Œä¿®æ­£å¯¾è±¡åˆ—ã€ã¯å†…å®¹ç¢ºèªç”¨ã®åˆ—ã§ã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯å«ã¾ã‚Œã¾ã›ã‚“ã€‚")
                            else:
                                # é€šå¸¸ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
                                # CSVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦å‡ºåŠ›
                                csv_output = io.StringIO()
                                data.to_csv(csv_output, index=False, encoding='utf-8-sig')
                                csv_data = csv_output.getvalue().encode('utf-8-sig')
                                
                                st.download_button(
                                    label=f"ğŸ“ {filename}",
                                    data=csv_data,
                                    file_name=filename,
                                    mime="text/csv",
                                    key=f"download_{filename}"
                                )
                                
                                # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                                with st.expander(f"ğŸ“‹ {filename} ã®å†…å®¹ã‚’ç¢ºèª"):
                                    st.dataframe(data, use_container_width=True)
                                    st.info(f"è¡Œæ•°: {len(data)}, åˆ—æ•°: {len(data.columns)}")

                    else:
                        st.warning("ä½œæˆå¯¾è±¡ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    


def format_for_import(main_data, original_data):
    """ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ç”¨ã«æ•´å½¢
    
    Args:
        main_data (pd.DataFrame): ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿
        original_data (pd.DataFrame): å·®åˆ†æ¤œå‡ºç”¨ãƒ‡ãƒ¼ã‚¿
    
    Returns:
        pd.DataFrame: æ•´å½¢å¾Œã®ãƒ‡ãƒ¼ã‚¿
    """
    formatted_data = main_data.copy()
    
    # æ•°å­—ã¸ç½®æ›
    binary_columns = ['å‚åŠ è€…ã®æ¡ä»¶(å¦Šå¨ )', 'å‚åŠ è€…ã®æ¡ä»¶(0æ­³)', 'å‚åŠ è€…ã®æ¡ä»¶(1æ­³)', 
                     'å‚åŠ è€…ã®æ¡ä»¶(1æ­³å¾ŒåŠ)', 'å‚åŠ è€…ã®æ¡ä»¶(2æ­³)', 'å‚åŠ è€…ã®æ¡ä»¶(2æ­³å¾ŒåŠ)', 
                     'å‚åŠ è€…ã®æ¡ä»¶(3æ­³)', 'å‚åŠ è€…ã®æ¡ä»¶(4æ­³)', 'å‚åŠ è€…ã®æ¡ä»¶(5æ­³)', 
                     'å‚åŠ è€…ã®æ¡ä»¶(6æ­³)', 'å‚åŠ è€…ã®æ¡ä»¶(ã©ãªãŸã§ã‚‚)', 'è¦ä¼šè²»', 
                     'å†Šå­æ²è¼‰å¯', 'HPæ²è¼‰å¯', 'ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿æ²è¼‰å¯']
    
    for col in binary_columns:
        if col in formatted_data.columns:
            # åˆ—ã‚’æ–‡å­—åˆ—å‹ã«å¤‰æ›ï¼ˆè­¦å‘Šã‚’å›é¿ï¼‰
            formatted_data[col] = formatted_data[col].astype(str)
            
            for idx, raw_value in formatted_data[col].items():
                # normalize_valueé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦çµ±ä¸€çš„ã«å‡¦ç†
                value = normalize_value(raw_value)
                
                # å€¤ã®å¤‰æ›
                if value == '' or value == '0':
                    formatted_data.at[idx, col] = '0'
                elif value == 'â—‹' or value == '1':
                    formatted_data.at[idx, col] = '1'
                else:
                    # ãã‚Œä»¥å¤–ã®å€¤ãŒå…¥ã£ã¦ã„ãŸå ´åˆã¯ã‚¨ãƒ©ãƒ¼æ‰±ã„
                    st.error(f"è¡Œ{idx+1}ã®{col}åˆ—ã«ç„¡åŠ¹ãªå€¤ãŒå«ã¾ã‚Œã¦ã„ã¾ã™: {value}")
                    formatted_data.at[idx, col] = '0'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã¨ã—ã¦0ã‚’è¨­å®š
    
    # å‚åŠ è€…ã®æ¡ä»¶(å¦Šå¨ å¾ŒåŠ)åˆ—ã«å‚åŠ è€…ã®æ¡ä»¶(å¦Šå¨ )åˆ—ã®å€¤ã‚’ã‚³ãƒ”ãƒ¼
    if 'å‚åŠ è€…ã®æ¡ä»¶(å¦Šå¨ )' in formatted_data.columns and 'å‚åŠ è€…ã®æ¡ä»¶(å¦Šå¨ å¾ŒåŠ)' in formatted_data.columns:
        formatted_data['å‚åŠ è€…ã®æ¡ä»¶(å¦Šå¨ å¾ŒåŠ)'] = formatted_data['å‚åŠ è€…ã®æ¡ä»¶(å¦Šå¨ )']
    
    # å…¥åŠ›ç¦æ­¢åˆ—ã®å€¤ã®å‰Šé™¤
    prohibited_columns = ['ç”³è¾¼æ–¹æ³•å‚™è€ƒ', 'æ´»å‹•æ—¥_å–¶æ¥­æ™‚é–“ãƒ©ãƒ™ãƒ«', 'æ´»å‹•æ—¥_å–¶æ¥­æ›œæ—¥ãƒ©ãƒ™ãƒ«']
    for col in prohibited_columns:
        if col in formatted_data.columns:
            formatted_data[col] = ''
    
    # å‚åŠ è€…ã®æ¡ä»¶(å‡ºç”£)ã¯ä¸€å¾‹ã€Œ0ã€ã§åŸ‹ã‚ã‚‹ï¼ˆå…¥åŠ›ç¦æ­¢åˆ—ã ãŒã€ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã¯ã€Œ0ã€ãŒå¿…è¦ï¼‰
    if 'å‚åŠ è€…ã®æ¡ä»¶(å‡ºç”£)' in formatted_data.columns:
        # åˆ—ã‚’æ–‡å­—åˆ—å‹ã«å¤‰æ›ã—ã¦ã‹ã‚‰å€¤ã‚’è¨­å®šï¼ˆè­¦å‘Šã‚’å›é¿ï¼‰
        formatted_data['å‚åŠ è€…ã®æ¡ä»¶(å‡ºç”£)'] = formatted_data['å‚åŠ è€…ã®æ¡ä»¶(å‡ºç”£)'].astype(str)
        formatted_data['å‚åŠ è€…ã®æ¡ä»¶(å‡ºç”£)'] = '0'
    
    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®ä¿®æ­£ï¼ˆå„ªå…ˆé †ä½ã«å¾“ã£ã¦å‡¦ç†ï¼‰
    for idx, row in formatted_data.iterrows():
        # ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦åˆ—ã®å€¤ã‚’æ­£è¦åŒ–
        status_value = normalize_value(row.get('ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦', ''))
        
        # HPæ²è¼‰å¯åˆ—ã®å€¤ã‚’æ­£è¦åŒ–
        hp_publish = normalize_value(row.get('HPæ²è¼‰å¯', ''))
        
        # å„ªå…ˆé †ä½ã«å¾“ã£ã¦ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’è¨­å®š
        # 1. ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦åˆ—ã®å€¤ãŒã€Œå‰Šé™¤ã€ã§ã‚ã‚‹ï¼šã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ—ã®å€¤ã‚’ã€Œprivateã€ã«ã™ã‚‹
        if status_value == 'å‰Šé™¤':
            formatted_data.at[idx, 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'] = 'private'
        # 2. ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦åˆ—ã®å€¤ãŒã€Œå‰Šé™¤ã€ã§ãªã„ ã‹ã¤ ç©ºæ¬„ã§ã‚ã‚‹ï¼šã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ—ã®å€¤ã‚’ã€Œpublishã€ã«ã™ã‚‹
        elif status_value != 'å‰Šé™¤' and status_value == '':
            formatted_data.at[idx, 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'] = 'publish'
        # 3. HPæ²è¼‰å¯åˆ—ã®å€¤ãŒ1ã§ã‚ã‚‹ï¼šã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ—ã®å€¤ã‚’ã€Œpublishã€ã«ã™ã‚‹
        elif hp_publish == '1':
            formatted_data.at[idx, 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'] = 'publish'
        # 4. HPæ²è¼‰å¯åˆ—ã®å€¤ãŒ0ã§ã‚ã‚‹ï¼šã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ—ã®å€¤ã‚’ã€Œprivateã€ã«ã™ã‚‹
        elif hp_publish == '0':
            formatted_data.at[idx, 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'] = 'private'
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        else:
            formatted_data.at[idx, 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'] = 'publish'
    
    # é †ç•ªã®ä¿®æ­£ï¼ˆå®Ÿéš›ã«å¤‰æ›´ãŒå¿…è¦ãªè¡Œã®ã¿å‡¦ç†ï¼‰
    formatted_data = formatted_data.reset_index(drop=True)
    
    # å…ƒãƒ‡ãƒ¼ã‚¿ã¨ã®é †ç•ªæ¯”è¼ƒç”¨ã«ã‚¹ãƒ©ãƒƒã‚°ã‚’ã‚­ãƒ¼ã¨ã—ãŸè¾æ›¸ã‚’ä½œæˆ
    original_order_dict = {}
    for idx, row in original_data.iterrows():
        slug = normalize_value(row.get('ã‚¹ãƒ©ãƒƒã‚°', ''))
        
        if slug:
            order = normalize_value(row.get('é †ç•ª', ''))
            original_order_dict[slug] = order
    
    # æ–°ã—ã„é †ç•ªã‚’è¨­å®š
    formatted_data['é †ç•ª'] = range(1, len(formatted_data) + 1)
    
    # é †ç•ªã®å·®åˆ†ãƒã‚§ãƒƒã‚¯ã¨ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦åˆ—ã®æ›´æ–°ï¼ˆå®Ÿéš›ã«å¤‰æ›´ãŒã‚ã£ãŸè¡Œã®ã¿ï¼‰
    for idx, row in formatted_data.iterrows():
        # ã‚¹ãƒ©ãƒƒã‚°ã®å€¤ã‚’æ­£è¦åŒ–
        slug = normalize_value(row.get('ã‚¹ãƒ©ãƒƒã‚°', ''))
        
        # ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ­£è¦åŒ–
        current_status = normalize_value(row.get('ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦', ''))
        
        # ã™ã§ã«ã€Œä¿®æ­£ã€ã€Œå‰Šé™¤ã€ã€Œæ–°è¦è¿½åŠ ã€ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ä¸Šæ›¸ãã—ãªã„
        if current_status in ['ä¿®æ­£', 'å‰Šé™¤', 'æ–°è¦è¿½åŠ ']:
            continue
        
        # ã‚¹ãƒ©ãƒƒã‚°ãŒå­˜åœ¨ã—ã€å…ƒãƒ‡ãƒ¼ã‚¿ã«ã‚‚å­˜åœ¨ã™ã‚‹å ´åˆã®ã¿é †ç•ªæ¯”è¼ƒ
        if slug and slug in original_order_dict:
            # ç¾åœ¨ã®é †ç•ªã‚’æ­£è¦åŒ–
            current_order = str(idx + 1)  # æ–°ã—ã„é †ç•ªï¼ˆ1ã‹ã‚‰å§‹ã¾ã‚‹é€£ç•ªï¼‰
            original_order = original_order_dict[slug]
            
            # é †ç•ªãŒå®Ÿéš›ã«å¤‰æ›´ã•ã‚ŒãŸå ´åˆã®ã¿ã€Œæ²è¼‰é †ã€ã‚’è¨­å®š
            if current_order != original_order:
                formatted_data.at[idx, 'ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦'] = 'æ²è¼‰é †'
    
    return formatted_data

def is_only_account_related_change(main_row, original_data):
    """ã‚¢ã‚«ã‚¦ãƒ³ãƒˆé–¢é€£ã®ã¿ã®å¤‰æ›´ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹é–¢æ•°
    
    Args:
        main_row: ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã®è¡Œ
        original_data: å·®åˆ†æ¤œå‡ºç”¨ãƒ‡ãƒ¼ã‚¿
    
    Returns:
        bool: ã‚¢ã‚«ã‚¦ãƒ³ãƒˆé–¢é€£ã®ã¿ã®å¤‰æ›´ã®å ´åˆTrue
    """
    # ã‚¹ãƒ©ãƒƒã‚°ã®å–å¾—
    slug = str(main_row.get('ã‚¹ãƒ©ãƒƒã‚°', '')).strip()
    
    if not slug:
        return False
    
    # å·®åˆ†æ¤œå‡ºç”¨ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åŒã˜ã‚¹ãƒ©ãƒƒã‚°ã®è¡Œã‚’å–å¾—
    original_row = original_data[original_data['ã‚¹ãƒ©ãƒƒã‚°'] == slug]
    
    if original_row.empty:
        return False
    
    original_row = original_row.iloc[0]
    
    # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆé–¢é€£åˆ—
    account_columns = ['ï½±ï½¶ï½³ï¾ï¾„ç™ºè¡Œæœ‰ç„¡', 'ï½±ï½¶ï½³ï¾ï¾„ç™ºè¡Œå¹´æœˆ', 'ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç™ºè¡Œã®ç™»éŒ²ç”¨ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹']
    
    # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆé–¢é€£ä»¥å¤–ã®åˆ—ã§å·®åˆ†ã‚’ãƒã‚§ãƒƒã‚¯
    excluded_columns = ['ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦'] + account_columns
    check_columns = [col for col in main_row.index if col not in excluded_columns]
    
    # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆé–¢é€£ä»¥å¤–ã«å¤‰æ›´ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    has_non_account_change = False
    for col in check_columns:
        if col in original_row.index:
            main_value = normalize_value(main_row.get(col, ''))
            original_value = normalize_value(original_row.get(col, ''))
            
            if main_value != original_value:
                has_non_account_change = True
                break
    
    # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆé–¢é€£ã«å¤‰æ›´ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    has_account_change = False
    for col in account_columns:
        if col in main_row.index and col in original_row.index:
            main_value = normalize_value(main_row.get(col, ''))
            original_value = normalize_value(original_row.get(col, ''))
            
            if main_value != original_value:
                has_account_change = True
                break
    
    # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆé–¢é€£ã®ã¿ã®å¤‰æ›´ã®å ´åˆï¼šã‚¢ã‚«ã‚¦ãƒ³ãƒˆé–¢é€£ã«å¤‰æ›´ãŒã‚ã‚Šã€ã‹ã¤ã‚¢ã‚«ã‚¦ãƒ³ãƒˆé–¢é€£ä»¥å¤–ã«å¤‰æ›´ãŒãªã„
    return has_account_change and not has_non_account_change

def detect_modified_columns(main_row, original_data, header_mapping):
    """ä¿®æ­£å¯¾è±¡åˆ—ã‚’æ¤œå‡ºã™ã‚‹é–¢æ•°ï¼ˆæ¤œè¨¼é–¢æ•°ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½¿ç”¨ï¼‰
    
    Args:
        main_row: ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã®è¡Œï¼ˆæ•´å½¢å‰ã®ãƒ‡ãƒ¼ã‚¿ï¼‰
        original_data: å·®åˆ†æ¤œå‡ºç”¨ãƒ‡ãƒ¼ã‚¿
        header_mapping: ãƒ˜ãƒƒãƒ€ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°è¾æ›¸
    
    Returns:
        str: ä¿®æ­£ã•ã‚ŒãŸåˆ—åã®ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šæ–‡å­—åˆ—
    """
    # ã‚¹ãƒ©ãƒƒã‚°ã®å–å¾—ï¼ˆæ¤œè¨¼é–¢æ•°ã¨åŒã˜å‡¦ç†ï¼‰
    slug = str(main_row.get('ã‚¹ãƒ©ãƒƒã‚°', '')).strip()
    
    if not slug:
        return ''
    
    # å·®åˆ†æ¤œå‡ºç”¨ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åŒã˜ã‚¹ãƒ©ãƒƒã‚°ã®è¡Œã‚’å–å¾—
    original_row = original_data[original_data['ã‚¹ãƒ©ãƒƒã‚°'] == slug]
    
    if original_row.empty:
        return ''
    
    original_row = original_row.iloc[0]
    modified_columns = []
    
    # ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦åˆ—ã¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆé–¢é€£åˆ—ä»¥å¤–ã®åˆ—ã§å·®åˆ†ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆæ¤œè¨¼é–¢æ•°ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
    excluded_columns = ['ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦', 'ï½±ï½¶ï½³ï¾ï¾„ç™ºè¡Œæœ‰ç„¡', 'ï½±ï½¶ï½³ï¾ï¾„ç™ºè¡Œå¹´æœˆ', 'ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç™ºè¡Œã®ç™»éŒ²ç”¨ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹']
    check_columns = [col for col in main_row.index if col not in excluded_columns]
    
    for col in check_columns:
        if col in original_row.index:
            # normalize_valueé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦å€¤ã‚’æ­£è¦åŒ–ï¼ˆæ¤œè¨¼é–¢æ•°ã¨åŒã˜å‡¦ç†ï¼‰
            main_value = normalize_value(main_row.get(col, ''))
            original_value = normalize_value(original_row.get(col, ''))
            
            if main_value != original_value:
                # ãƒ˜ãƒƒãƒ€ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°ãŒã‚ã‚‹å ´åˆã¯å¤‰æ›å¾Œã®åå‰ã‚’ä½¿ç”¨
                display_col = header_mapping.get(col, col)
                modified_columns.append(display_col)
    
    return ', '.join(modified_columns)

def create_import_files(formatted_data, original_data, user_data, municipality, main_data=None):
    """ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
    
    Args:
        formatted_data (pd.DataFrame): æ•´å½¢æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
        original_data (pd.DataFrame): å·®åˆ†æ¤œå‡ºç”¨ãƒ‡ãƒ¼ã‚¿
        user_data (pd.DataFrame): ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿
        municipality (str): è‡ªæ²»ä½“å
        main_data (pd.DataFrame, optional): æ•´å½¢å‰ã®ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ï¼ˆä¿®æ­£å¯¾è±¡åˆ—æ¤œå‡ºç”¨ï¼‰
    
    Returns:
        dict: ä½œæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®è¾æ›¸
    """
    current_date = datetime.datetime.now().strftime("%Y%m%d")
    current_month = datetime.datetime.now().month
    files = {}
    
    # è‚²å…ã‚µãƒ¼ã‚¯ãƒ«ç”¨ãƒ‡ãƒ¼ã‚¿ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼
    circle_template_headers = [
        'ã‚µãƒ¼ã‚¯ãƒ«å', 'ã‚¹ãƒ©ãƒƒã‚°', 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', 'æ´»å‹•ç¨®åˆ¥', 'æ¦‚è¦',
        'å¯¾è±¡å¹´é½¢(å¦Šå¨ å‰åŠ)', 'å¯¾è±¡å¹´é½¢(å¦Šå¨ å¾ŒåŠ)', 'å¯¾è±¡å¹´é½¢(å‡ºç”£)',
        'å¯¾è±¡å¹´é½¢(0æ­³)', 'å¯¾è±¡å¹´é½¢(1æ­³å‰åŠ)', 'å¯¾è±¡å¹´é½¢(1æ­³å¾ŒåŠ)',
        'å¯¾è±¡å¹´é½¢(2æ­³å‰åŠ)', 'å¯¾è±¡å¹´é½¢(2æ­³å¾ŒåŠ)', 'å¯¾è±¡å¹´é½¢(3æ­³)',
        'å¯¾è±¡å¹´é½¢(4æ­³)', 'å¯¾è±¡å¹´é½¢(5æ­³)', 'å¯¾è±¡å¹´é½¢(6æ­³(å°±å­¦å‰))',
        'å¯¾è±¡å¹´é½¢(6æ­³(å°±å­¦å¾Œ))', 'æ´»å‹•å ´æ‰€', 'ç”³è¾¼æ–¹æ³•', 'ç”³è¾¼æ–¹æ³•å‚™è€ƒ',
        'ç”³è¾¼å…ˆé›»è©±ç•ªå·', 'Eãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹', 'è¦ä¼šè²»', 'ä¼šè²»', 'Webã‚µã‚¤ãƒˆ',
        'æ´»å‹•æ—¥_å–¶æ¥­æ›œæ—¥', 'æ´»å‹•æ—¥_é–‹å§‹æ™‚é–“', 'æ´»å‹•æ—¥_çµ‚äº†æ™‚é–“',
        'æ´»å‹•æ—¥_å–¶æ¥­æ™‚é–“ãƒ©ãƒ™ãƒ«', 'æ´»å‹•æ—¥_å–¶æ¥­æ›œæ—¥ãƒ©ãƒ™ãƒ«', 'æ´»å‹•æ—¥_å‚™è€ƒ',
        'ä»£è¡¨è€…', 'å›£ä½“å', 'å›£ä½“åï¼ˆãµã‚ŠãŒãªï¼‰', 'å¹¼ç¨šåœ’ãƒ»ä¿è‚²åœ’ãƒã‚§ãƒƒã‚¯',
        'å†Šå­æ²è¼‰å¯', 'HPæ²è¼‰å¯', 'ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿æ²è¼‰å¯', 'å°å­¦æ ¡åŒº',
        'å°å­¦æ ¡åŒºï¼ˆãµã‚ŠãŒãªï¼‰', 'ä»£è¡¨è€…å', 'ä»£è¡¨è€…åï¼ˆãµã‚ŠãŒãªï¼‰',
        'ä»£è¡¨è€…éƒµä¾¿ç•ªå·', 'ä»£è¡¨è€…ä½æ‰€', 'ä»£è¡¨è€…é›»è©±ç•ªå·', 'ä»£è¡¨è€…FAX',
        'ä»£è¡¨è€…æºå¸¯ç•ªå·', 'è¨˜å…¥è€…', 'é †ç•ª'
    ]
    
    # CSVãƒ˜ãƒƒãƒ€ãƒ¼ã¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼ã®ãƒãƒƒãƒ”ãƒ³ã‚°
    header_mapping = {
        # å‚åŠ è€…ã®æ¡ä»¶ç³»ã®åˆ—åå¤‰æ›
        'å‚åŠ è€…ã®æ¡ä»¶(å¦Šå¨ )': 'å¯¾è±¡å¹´é½¢(å¦Šå¨ å‰åŠ)',
        'å‚åŠ è€…ã®æ¡ä»¶(å¦Šå¨ å¾ŒåŠ)': 'å¯¾è±¡å¹´é½¢(å¦Šå¨ å¾ŒåŠ)',
        'å‚åŠ è€…ã®æ¡ä»¶(å‡ºç”£)': 'å¯¾è±¡å¹´é½¢(å‡ºç”£)',
        'å‚åŠ è€…ã®æ¡ä»¶(0æ­³)': 'å¯¾è±¡å¹´é½¢(0æ­³)',
        'å‚åŠ è€…ã®æ¡ä»¶(1æ­³)': 'å¯¾è±¡å¹´é½¢(1æ­³å‰åŠ)',
        'å‚åŠ è€…ã®æ¡ä»¶(1æ­³å¾ŒåŠ)': 'å¯¾è±¡å¹´é½¢(1æ­³å¾ŒåŠ)',
        'å‚åŠ è€…ã®æ¡ä»¶(2æ­³)': 'å¯¾è±¡å¹´é½¢(2æ­³å‰åŠ)',
        'å‚åŠ è€…ã®æ¡ä»¶(2æ­³å¾ŒåŠ)': 'å¯¾è±¡å¹´é½¢(2æ­³å¾ŒåŠ)',
        'å‚åŠ è€…ã®æ¡ä»¶(3æ­³)': 'å¯¾è±¡å¹´é½¢(3æ­³)',
        'å‚åŠ è€…ã®æ¡ä»¶(4æ­³)': 'å¯¾è±¡å¹´é½¢(4æ­³)',
        'å‚åŠ è€…ã®æ¡ä»¶(5æ­³)': 'å¯¾è±¡å¹´é½¢(5æ­³)',
        'å‚åŠ è€…ã®æ¡ä»¶(6æ­³)': 'å¯¾è±¡å¹´é½¢(6æ­³(å°±å­¦å‰))',
        'å‚åŠ è€…ã®æ¡ä»¶(ã©ãªãŸã§ã‚‚)': 'å¯¾è±¡å¹´é½¢(6æ­³(å°±å­¦å¾Œ))',
        # ãã®ä»–ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã¯åŒã˜åå‰ãªã®ã§ãƒãƒƒãƒ”ãƒ³ã‚°ä¸è¦
    }
    
    # æ–°è¦è¿½åŠ ã®è‚²å…ã‚µãƒ¼ã‚¯ãƒ«
    new_circles = formatted_data[formatted_data['ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦'] == 'æ–°è¦è¿½åŠ ']
    if not new_circles.empty:
        # ãƒ˜ãƒƒãƒ€ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆCSVã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼ã«å¤‰æ›ï¼‰
        # äº‹å‰ã«DataFrameã®æ§‹é€ ã‚’å®šç¾©ï¼ˆå…¨ã¦æ–‡å­—åˆ—å‹ã¨ã—ã¦åˆæœŸåŒ–ï¼‰
        new_circles_mapped = pd.DataFrame(index=new_circles.index, 
                                        columns=circle_template_headers, 
                                        dtype=str)
        new_circles_mapped = new_circles_mapped.fillna('')
        
        for template_header in circle_template_headers:
            # ãƒãƒƒãƒ”ãƒ³ã‚°ãŒã‚ã‚‹å ´åˆã¯å…ƒã®ãƒ˜ãƒƒãƒ€ãƒ¼åã‚’ä½¿ç”¨
            csv_header = None
            for csv_col, template_col in header_mapping.items():
                if template_col == template_header:
                    csv_header = csv_col
                    break
            
            # ãƒãƒƒãƒ”ãƒ³ã‚°ãŒãªã„å ´åˆã¯åŒã˜åå‰ã‚’ä½¿ç”¨
            if csv_header is None:
                csv_header = template_header
            
            if csv_header in new_circles.columns:
                # æ¬ æå€¤ã‚’é©åˆ‡ã«å‡¦ç†ã—ã¦ä»£å…¥
                series = new_circles[csv_header].fillna('').astype(str)
                # 'nan'æ–‡å­—åˆ—ã‚’ç©ºæ–‡å­—ã«ç½®æ›
                series = series.replace(['nan', 'None', '<NA>'], '')
                new_circles_mapped[template_header] = series
            else:
                new_circles_mapped[template_header] = ''
        
        files[f"{municipality}è‚²å…ã‚µãƒ¼ã‚¯ãƒ«{current_month}æœˆ_æ–°è¦_{current_date}.csv"] = new_circles_mapped
    
    # ä¿®æ­£ã®è‚²å…ã‚µãƒ¼ã‚¯ãƒ«ï¼ˆæ˜ç¤ºçš„ã«æŒ‡å®šã•ã‚ŒãŸè¡Œã®ã¿ï¼‰
    # æ˜ç¤ºçš„ã«ä¿®æ­£ãƒ»å‰Šé™¤ãƒ»æ²è¼‰é †ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹è¡Œã®ã¿ã‚’ä¿®æ­£CSVã«å«ã‚ã‚‹
    # æš—é»™çš„ãªä¿®æ­£æ¤œå‡ºã¯è¡Œã‚ãªã„ï¼ˆã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿æ•´å½¢å‡¦ç†ã«ã‚ˆã‚‹å¤‰æ›´ã‚’é™¤å¤–ã™ã‚‹ãŸã‚ï¼‰
    # ãŸã ã—ã€ã€Œä¿®æ­£ã€ã®å ´åˆã¯ã‚¢ã‚«ã‚¦ãƒ³ãƒˆé–¢é€£ã®ã¿ã®å¤‰æ›´ã¯é™¤å¤–ã™ã‚‹
    candidate_circles = formatted_data[formatted_data['ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦'].isin(['ä¿®æ­£', 'å‰Šé™¤', 'æ²è¼‰é †'])]
    
    # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆé–¢é€£ã®ã¿ã®å¤‰æ›´ã‚’é™¤å¤–
    modified_circles_list = []
    for idx, row in candidate_circles.iterrows():
        status = normalize_value(row.get('ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦', ''))
        
        if status == 'ä¿®æ­£':
            # main_dataãŒæä¾›ã•ã‚Œã¦ã„ã‚‹å ´åˆã€æ•´å½¢å‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ãƒã‚§ãƒƒã‚¯
            if main_data is not None and idx in main_data.index:
                main_row = main_data.loc[idx]
                # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆé–¢é€£ã®ã¿ã®å¤‰æ›´ã®å ´åˆã¯é™¤å¤–
                if is_only_account_related_change(main_row, original_data):
                    continue
            else:
                # main_dataãŒæä¾›ã•ã‚Œã¦ã„ãªã„å ´åˆã€formatted_dataã‚’ä½¿ç”¨ã—ã¦ãƒã‚§ãƒƒã‚¯
                if is_only_account_related_change(row, original_data):
                    continue
        
        # å‰Šé™¤ãƒ»æ²è¼‰é †ã®å ´åˆã€ã¾ãŸã¯ã‚¢ã‚«ã‚¦ãƒ³ãƒˆé–¢é€£ä»¥å¤–ã®å¤‰æ›´ãŒã‚ã‚‹ä¿®æ­£ã®å ´åˆã¯å«ã‚ã‚‹
        modified_circles_list.append(idx)
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒªã‚¹ãƒˆã‹ã‚‰è©²å½“è¡Œã‚’æŠ½å‡º
    if modified_circles_list:
        modified_circles = formatted_data.loc[modified_circles_list]
    else:
        modified_circles = pd.DataFrame()
    if not modified_circles.empty:
        # ãƒ˜ãƒƒãƒ€ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆCSVã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼ã«å¤‰æ›ï¼‰
        # äº‹å‰ã«DataFrameã®æ§‹é€ ã‚’å®šç¾©ï¼ˆå…¨ã¦æ–‡å­—åˆ—å‹ã¨ã—ã¦åˆæœŸåŒ–ï¼‰
        modified_circles_mapped = pd.DataFrame(index=modified_circles.index, 
                                             columns=circle_template_headers + ['ä¿®æ­£å¯¾è±¡åˆ—'], 
                                             dtype=str)
        modified_circles_mapped = modified_circles_mapped.fillna('')
        
        for template_header in circle_template_headers:
            # ãƒãƒƒãƒ”ãƒ³ã‚°ãŒã‚ã‚‹å ´åˆã¯å…ƒã®ãƒ˜ãƒƒãƒ€ãƒ¼åã‚’ä½¿ç”¨
            csv_header = None
            for csv_col, template_col in header_mapping.items():
                if template_col == template_header:
                    csv_header = csv_col
                    break
            
            # ãƒãƒƒãƒ”ãƒ³ã‚°ãŒãªã„å ´åˆã¯åŒã˜åå‰ã‚’ä½¿ç”¨
            if csv_header is None:
                csv_header = template_header
            
            if csv_header in modified_circles.columns:
                # æ¬ æå€¤ã‚’é©åˆ‡ã«å‡¦ç†ã—ã¦ä»£å…¥
                series = modified_circles[csv_header].fillna('').astype(str)
                # 'nan'æ–‡å­—åˆ—ã‚’ç©ºæ–‡å­—ã«ç½®æ›
                series = series.replace(['nan', 'None', '<NA>'], '')
                modified_circles_mapped[template_header] = series
            else:
                modified_circles_mapped[template_header] = ''
        
        # ä¿®æ­£å¯¾è±¡åˆ—ã‚’æ¤œå‡ºã—ã¦è¿½åŠ ï¼ˆæ•´å½¢å‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰
        for idx, row in modified_circles.iterrows():
            if main_data is not None and idx in main_data.index:
                # æ•´å½¢å‰ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆmain_dataï¼‰ã‚’ä½¿ç”¨ã—ã¦å·®åˆ†ã‚’æ¤œå‡º
                main_row = main_data.loc[idx]
                modified_columns = detect_modified_columns(main_row, original_data, header_mapping)
            else:
                # main_dataãŒæä¾›ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ç©ºæ–‡å­—åˆ—
                modified_columns = ''
            modified_circles_mapped.at[idx, 'ä¿®æ­£å¯¾è±¡åˆ—'] = modified_columns
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆä¿®æ­£å¯¾è±¡åˆ—ã‚’é™¤å¤–ï¼‰
        download_data = modified_circles_mapped.drop(columns=['ä¿®æ­£å¯¾è±¡åˆ—'])
        
        # ãƒ•ã‚¡ã‚¤ãƒ«è¾æ›¸ã«ã¯è¡¨ç¤ºç”¨ï¼ˆä¿®æ­£å¯¾è±¡åˆ—å«ã‚€ï¼‰ã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ï¼ˆä¿®æ­£å¯¾è±¡åˆ—é™¤å¤–ï¼‰ã®ä¸¡æ–¹ã‚’ä¿å­˜
        files[f"{municipality}è‚²å…ã‚µãƒ¼ã‚¯ãƒ«{current_month}æœˆ_ä¿®æ­£_{current_date}.csv"] = {
            'display_data': modified_circles_mapped,  # è¡¨ç¤ºç”¨ï¼ˆä¿®æ­£å¯¾è±¡åˆ—å«ã‚€ï¼‰
            'download_data': download_data  # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ï¼ˆä¿®æ­£å¯¾è±¡åˆ—é™¤å¤–ï¼‰
        }
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼æ–°è¦è¿½åŠ ãƒ»ä¿®æ­£ã®å‡¦ç†
    user_import_data = create_user_import_data(formatted_data, original_data, user_data)
    if not user_import_data.empty:
        files[f"{municipality}{current_month}æœˆ_ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™»éŒ²{current_date}.csv"] = user_import_data
    
    return files

def create_user_import_data(formatted_data, original_data, user_data):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
    
    Args:
        formatted_data (pd.DataFrame): æ•´å½¢æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
        original_data (pd.DataFrame): å·®åˆ†æ¤œå‡ºç”¨ãƒ‡ãƒ¼ã‚¿
        user_data (pd.DataFrame): ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿
    
    Returns:
        pd.DataFrame: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿
    """
    user_import_df = pd.DataFrame(columns=['åå‰', 'ã‚¹ãƒ©ãƒƒã‚°', 'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹', 'è‡ªå·±ç´¹ä»‹', 'ç¨®é¡', 'Webã‚µã‚¤ãƒˆ', 'ç”»åƒ'])
    
    # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç™ºè¡Œæœ‰ç„¡ã®æ¡ä»¶ã‚’æ­£è¦åŒ–ã—ã¦è©•ä¾¡
    def is_account_issued(value):
        if pd.isna(value):
            return False
        value_str = str(value).strip()
        if value_str in ['nan', 'None', '<NA>']:
            return False
        return value_str == 'â—‹'
    
    # ï½±ï½¶ï½³ï¾ï¾„ç™ºè¡Œæœ‰ç„¡åˆ—ã®å·®åˆ†ãƒã‚§ãƒƒã‚¯é–¢æ•°
    def has_account_status_changed(row, original_data):
        """ï½±ï½¶ï½³ï¾ï¾„ç™ºè¡Œæœ‰ç„¡åˆ—ã®å€¤ãŒå·®åˆ†æ¤œå‡ºç”¨ãƒ‡ãƒ¼ã‚¿ã¨ç•°ãªã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        main_slug = normalize_value(row.get('ã‚¹ãƒ©ãƒƒã‚°', ''))
        
        if main_slug:  # ã‚¹ãƒ©ãƒƒã‚°ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿å‡¦ç†
            # å·®åˆ†æ¤œå‡ºç”¨ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åŒã˜ã‚¹ãƒ©ãƒƒã‚°ã®è¡Œã‚’å–å¾—
            original_row = original_data[original_data['ã‚¹ãƒ©ãƒƒã‚°'] == main_slug]
            
            if not original_row.empty:
                # ï½±ï½¶ï½³ï¾ï¾„ç™ºè¡Œæœ‰ç„¡ã®æ¯”è¼ƒ
                main_account_status = is_account_issued(row.get('ï½±ï½¶ï½³ï¾ï¾„ç™ºè¡Œæœ‰ç„¡', ''))
                original_account_status = is_account_issued(original_row.iloc[0].get('ï½±ï½¶ï½³ï¾ï¾„ç™ºè¡Œæœ‰ç„¡', ''))
                
                return main_account_status != original_account_status
        
        return False
    
    # æ–°è¦è¿½åŠ ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    # æ¡ä»¶ã‚’ä¿®æ­£ï¼š
    # æ¡ä»¶1ï¼ˆå¿…é ˆï¼‰: ï½±ï½¶ï½³ï¾ï¾„ç™ºè¡Œæœ‰ç„¡åˆ— = 'â—‹' ã‹ã¤ ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç™ºè¡Œã®ç™»éŒ²ç”¨ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹åˆ—ã«ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹
    # æ¡ä»¶2: ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦åˆ—ã®å€¤ãŒã€Œæ–°è¦è¿½åŠ ã€ã§ã‚ã‚‹
    # æ¡ä»¶3: ï½±ï½¶ï½³ï¾ï¾„ç™ºè¡Œæœ‰ç„¡åˆ—ã®å€¤ãŒå·®åˆ†æ¤œå‡ºç”¨ãƒ‡ãƒ¼ã‚¿ã¨ç•°ãªã‚‹
    # 
    # ä½œæˆã•ã‚Œã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼š
    # - æ¡ä»¶1 ã‹ã¤ æ¡ä»¶2
    # - æ¡ä»¶1 ã‹ã¤ æ¡ä»¶3
    
    # æ¡ä»¶1ï¼ˆå¿…é ˆï¼‰: ï½±ï½¶ï½³ï¾ï¾„ç™ºè¡Œæœ‰ç„¡åˆ— = 'â—‹' ã‹ã¤ ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç™ºè¡Œã®ç™»éŒ²ç”¨ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹åˆ—ã«ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹
    condition1 = (
        formatted_data['ï½±ï½¶ï½³ï¾ï¾„ç™ºè¡Œæœ‰ç„¡'].apply(is_account_issued) &
        formatted_data['ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç™ºè¡Œã®ç™»éŒ²ç”¨ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹'].apply(lambda x: normalize_value(x) != '')
    )
    
    # æ¡ä»¶2: ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦åˆ—ã®å€¤ãŒã€Œæ–°è¦è¿½åŠ ã€ã§ã‚ã‚‹
    condition2 = formatted_data['ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦'].apply(lambda x: normalize_value(x) == 'æ–°è¦è¿½åŠ ')
    
    # æ¡ä»¶3: ï½±ï½¶ï½³ï¾ï¾„ç™ºè¡Œæœ‰ç„¡åˆ—ã®å€¤ãŒå·®åˆ†æ¤œå‡ºç”¨ãƒ‡ãƒ¼ã‚¿ã¨ç•°ãªã‚‹
    condition3 = formatted_data.apply(lambda row: has_account_status_changed(row, original_data), axis=1)
    
    # æ¡ä»¶1ãŒå¿…é ˆã§ã€ã‹ã¤ï¼ˆæ¡ä»¶2ã¾ãŸã¯æ¡ä»¶3ï¼‰ã‚’æº€ãŸã™è¡Œã‚’æŠ½å‡º
    new_accounts = formatted_data[condition1 & (condition2 | condition3)]
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜ï¼ˆè¡¨ç¤ºã¯å¾Œã§è¡Œã†ï¼‰
    if st.session_state.get('debug_mode', False):
        # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç™ºè¡Œæœ‰ç„¡ã®çŠ¶æ³
        account_issued_count = formatted_data['ï½±ï½¶ï½³ï¾ï¾„ç™ºè¡Œæœ‰ç„¡'].apply(is_account_issued).sum()
        
        # ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹è¨˜è¼‰ã®çŠ¶æ³
        email_filled_count = formatted_data['ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç™ºè¡Œã®ç™»éŒ²ç”¨ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹'].apply(lambda x: normalize_value(x) != '').sum()
        
        # æ–°è¦è¿½åŠ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®çŠ¶æ³
        new_status_count = condition2.sum()
        
        # ï½±ï½¶ï½³ï¾ï¾„ç™ºè¡Œæœ‰ç„¡å·®åˆ†ã®çŠ¶æ³
        account_diff_count = condition3.sum()
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
        debug_info = {
            'total_rows': len(formatted_data),
            'account_issued_count': account_issued_count,
            'email_filled_count': email_filled_count,
            'new_status_count': new_status_count,
            'account_diff_count': account_diff_count,
            'condition1_count': condition1.sum(),
            'condition2_count': condition2.sum(),
            'condition3_count': condition3.sum(),
            'new_accounts_count': len(new_accounts),
            'new_accounts_sample': new_accounts[['ã‚µãƒ¼ã‚¯ãƒ«å', 'ï½±ï½¶ï½³ï¾ï¾„ç™ºè¡Œæœ‰ç„¡', 'ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç™ºè¡Œã®ç™»éŒ²ç”¨ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹', 'ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦']].head() if len(new_accounts) > 0 else None,
            'account_values': formatted_data['ï½±ï½¶ï½³ï¾ï¾„ç™ºè¡Œæœ‰ç„¡'].value_counts() if len(new_accounts) == 0 else None,
        }
        st.session_state.user_csv_debug_info = debug_info
    
    # ä¿®æ­£ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ä½œæˆï¼ˆå…ˆã«å®Ÿè¡Œï¼‰
    modified_users_df, modified_row_indices = create_modified_user_data(formatted_data, original_data, user_data)
    
    # ä¿®æ­£å¯¾è±¡ã¨ãªã£ãŸè¡Œã‚’æ–°è¦è¿½åŠ ã‹ã‚‰é™¤å¤–
    if modified_row_indices:
        # ä¿®æ­£å¯¾è±¡ã®è¡Œã‚’é™¤å¤–ã—ãŸnew_accountsã‚’ä½œæˆ
        filtered_new_accounts = new_accounts[~new_accounts.index.isin(modified_row_indices)]
    else:
        # ä¿®æ­£å¯¾è±¡ãŒãªã„å ´åˆã¯å…ƒã®new_accountsã‚’ãã®ã¾ã¾ä½¿ç”¨
        filtered_new_accounts = new_accounts
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆæ™‚ã®ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’åé›†
    user_creation_errors = []
    
    # æ—¢å­˜ã®ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã®ã‚»ãƒƒãƒˆã‚’ä½œæˆï¼ˆé«˜é€ŸåŒ–ã®ãŸã‚ï¼‰
    existing_emails = set(user_data['ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹'].astype(str))
    
    # åŒã˜ãƒãƒƒãƒå†…ã§ã®ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹é‡è¤‡ãƒã‚§ãƒƒã‚¯ç”¨ã®ã‚»ãƒƒãƒˆ
    batch_emails = set()
    
    # æ–°è¦è¿½åŠ ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ä½œæˆï¼ˆä¿®æ­£å¯¾è±¡ã‚’é™¤å¤–å¾Œï¼‰
    if not filtered_new_accounts.empty:
        # æ—¢å­˜ã®ã‚¹ãƒ©ãƒƒã‚°ã‹ã‚‰æ¬¡ã®ç•ªå·ã‚’å–å¾—
        existing_slugs = user_data['ã‚¹ãƒ©ãƒƒã‚°'].astype(str)
        cs_numbers = []
        for slug in existing_slugs:
            if slug.startswith('cs') and slug[2:].isdigit():
                num = int(slug[2:])
                if 1 <= num <= 9998:  # cs9999ã¯é™¤å¤–
                    cs_numbers.append(num)
        
        next_number = max(cs_numbers) + 1 if cs_numbers else 1
        
        for idx, row in filtered_new_accounts.iterrows():
            # ã‚µãƒ¼ã‚¯ãƒ«åã®æ­£è¦åŒ–
            raw_circle_name = row.get('ã‚µãƒ¼ã‚¯ãƒ«å', '')
            if pd.isna(raw_circle_name):
                circle_name = ''
            else:
                circle_name = str(raw_circle_name).strip()
                if circle_name in ['nan', 'None', '<NA>']:
                    circle_name = ''
            
            # ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã®æ­£è¦åŒ–
            raw_email = row.get('ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç™ºè¡Œã®ç™»éŒ²ç”¨ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹', '')
            if pd.isna(raw_email):
                email = ''
            else:
                email = str(raw_email).strip()
                if email in ['nan', 'None', '<NA>']:
                    email = ''
            
            # ï½±ï½¶ï½³ï¾ï¾„ç™ºè¡Œæœ‰ç„¡ã®å€¤ã‚’å–å¾—
            account_issued = is_account_issued(row.get('ï½±ï½¶ï½³ï¾ï¾„ç™ºè¡Œæœ‰ç„¡', ''))
            
            # ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦ã®å€¤ã‚’å–å¾—
            modification_status = normalize_value(row.get('ä¿®æ­£ãƒ»å‰Šé™¤æ–°è¦', ''))
            
            # å¿…é ˆé …ç›®ã®ãƒã‚§ãƒƒã‚¯
            if not circle_name or not email:
                # æ¡ä»¶1ã‚’æº€ãŸã™å¯¾è±¡è€…ï¼ˆï½±ï½¶ï½³ï¾ï¾„ç™ºè¡Œæœ‰ç„¡=â—‹ã‹ã¤ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹è¨˜è¼‰äºˆå®šï¼‰ã«å¯¾ã—ã¦ã®ã¿ã‚¨ãƒ©ãƒ¼æ‰±ã„
                # ãŸã ã—ã€æ—¢ã«filtered_new_accountsã§æ¡ä»¶1ã‚’æº€ãŸã™è¡Œã®ã¿ãŒæŠ½å‡ºã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€
                # ã“ã“ã«æ¥ã‚‹è¡Œã¯å…¨ã¦æ¡ä»¶1ã‚’æº€ãŸã™è¡Œã§ã‚ã‚‹
                missing_fields = []
                if not circle_name:
                    missing_fields.append('ã‚µãƒ¼ã‚¯ãƒ«å')
                if not email:
                    missing_fields.append('ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç™ºè¡Œã®ç™»éŒ²ç”¨ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹')
                
                user_creation_errors.append({
                    'è¡Œç•ªå·': idx + 1,
                    'ã‚µãƒ¼ã‚¯ãƒ«å': circle_name if circle_name else 'ï¼ˆç©ºæ¬„ï¼‰',
                    'ã‚¨ãƒ©ãƒ¼å†…å®¹': f"{', '.join(missing_fields)}ãŒç©ºæ¬„ã§ã™",
                    'ã‚¨ãƒ©ãƒ¼ç¨®åˆ¥': 'å¿…é ˆé …ç›®ä¸è¶³'
                })
                continue
            
            # ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆæ—¢å­˜ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã¨ã®é‡è¤‡ï¼‰
            if email in existing_emails:
                user_creation_errors.append({
                    'è¡Œç•ªå·': idx + 1,
                    'ã‚µãƒ¼ã‚¯ãƒ«å': circle_name,
                    'ã‚¨ãƒ©ãƒ¼å†…å®¹': f"ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ '{email}' ã¯æ—¢ã«ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã™",
                    'ã‚¨ãƒ©ãƒ¼ç¨®åˆ¥': 'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹é‡è¤‡'
                })
                continue
            
            # ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆåŒã˜ãƒãƒƒãƒå†…ã§ã®é‡è¤‡ï¼‰
            if email in batch_emails:
                user_creation_errors.append({
                    'è¡Œç•ªå·': idx + 1,
                    'ã‚µãƒ¼ã‚¯ãƒ«å': circle_name,
                    'ã‚¨ãƒ©ãƒ¼å†…å®¹': f"ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ '{email}' ã¯åŒã˜ãƒ•ã‚¡ã‚¤ãƒ«å†…ã®ä»–ã®è¡Œã¨é‡è¤‡ã—ã¦ã„ã¾ã™",
                    'ã‚¨ãƒ©ãƒ¼ç¨®åˆ¥': 'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹é‡è¤‡'
                })
                continue
            
            # å‡¦ç†æ¸ˆã¿ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã¨ã—ã¦è¨˜éŒ²
            batch_emails.add(email)
            
            new_slug = f"cs{next_number:04d}"
            
            new_user = {
                'åå‰': circle_name,
                'ã‚¹ãƒ©ãƒƒã‚°': new_slug,
                'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹': email,
                'è‡ªå·±ç´¹ä»‹': '',
                'ç¨®é¡': 'blog_writer',
                'Webã‚µã‚¤ãƒˆ': '',
                'ç”»åƒ': ''
            }
            
            user_import_df = pd.concat([user_import_df, pd.DataFrame([new_user])], ignore_index=True)
            next_number += 1
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹å ´åˆã¯è­¦å‘Šæƒ…å ±ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
    if user_creation_errors:
        error_warning = "### âš ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆæ™‚ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ\n\n"
        error_warning += f"**{len(user_creation_errors)}ä»¶ã®ã‚¨ãƒ©ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚ä»¥ä¸‹ã®è¡Œã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä½œæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼š**\n\n"
        
        # ã‚¨ãƒ©ãƒ¼ç¨®åˆ¥ã”ã¨ã«åˆ†é¡
        missing_fields_errors = [e for e in user_creation_errors if e['ã‚¨ãƒ©ãƒ¼ç¨®åˆ¥'] == 'å¿…é ˆé …ç›®ä¸è¶³']
        duplicate_email_errors = [e for e in user_creation_errors if e['ã‚¨ãƒ©ãƒ¼ç¨®åˆ¥'] == 'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹é‡è¤‡']
        
        if missing_fields_errors:
            error_warning += "**ğŸ“ å¿…é ˆé …ç›®ä¸è¶³:**\n"
            for error in missing_fields_errors:
                error_warning += f"- è¡Œ{error['è¡Œç•ªå·']}: {error['ã‚µãƒ¼ã‚¯ãƒ«å']} - {error['ã‚¨ãƒ©ãƒ¼å†…å®¹']}\n"
            error_warning += "\n"
        
        if duplicate_email_errors:
            error_warning += "**ğŸ“§ ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹é‡è¤‡:**\n"
            for error in duplicate_email_errors:
                error_warning += f"- è¡Œ{error['è¡Œç•ªå·']}: {error['ã‚µãƒ¼ã‚¯ãƒ«å']} - {error['ã‚¨ãƒ©ãƒ¼å†…å®¹']}\n"
            error_warning += "\n"
        
        error_warning += "**å¯¾å‡¦æ–¹æ³•:**\n"
        error_warning += "1. å¿…é ˆé …ç›®ä¸è¶³ï¼šã‚µãƒ¼ã‚¯ãƒ«åã¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç™ºè¡Œã®ç™»éŒ²ç”¨ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„\n"
        error_warning += "2. ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹é‡è¤‡ï¼šæ—¢å­˜ã¨ç•°ãªã‚‹ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’ä½¿ç”¨ã™ã‚‹ã‹ã€æ—¢å­˜ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¿®æ­£ã‚’æ¤œè¨ã—ã¦ãã ã•ã„\n"
        error_warning += "3. åŒã˜ãƒ•ã‚¡ã‚¤ãƒ«å†…ã§ã®é‡è¤‡ï¼šé‡è¤‡ã™ã‚‹ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„\n"
        
        # è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
        if 'user_creation_warning' not in st.session_state:
            st.session_state.user_creation_warning = error_warning
    
    # æ–°è¦ã¨ä¿®æ­£ã‚’ãƒãƒ¼ã‚¸
    if not modified_users_df.empty:
        user_import_df = pd.concat([user_import_df, modified_users_df], ignore_index=True)
    
    return user_import_df

def create_modified_user_data(main_data, original_data, user_data):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¿®æ­£ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
    
    Args:
        main_data (pd.DataFrame): ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿
        original_data (pd.DataFrame): å·®åˆ†æ¤œå‡ºç”¨ãƒ‡ãƒ¼ã‚¿
        user_data (pd.DataFrame): ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿
    
    Returns:
        tuple: (ä¿®æ­£ã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿, ä¿®æ­£å¯¾è±¡è¡Œã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒªã‚¹ãƒˆ)
    """
    modified_users_df = pd.DataFrame(columns=['åå‰', 'ã‚¹ãƒ©ãƒƒã‚°', 'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹', 'è‡ªå·±ç´¹ä»‹', 'ç¨®é¡', 'Webã‚µã‚¤ãƒˆ', 'ç”»åƒ'])
    
    # å·®åˆ†è¡¨ç¤ºç”¨ã®ãƒªã‚¹ãƒˆ
    modification_details = []
    
    # ä¿®æ­£å¯¾è±¡è¡Œã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¨˜éŒ²
    modified_row_indices = []
    
    # 1. ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç™ºè¡Œã®ç™»éŒ²ç”¨ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹åˆ—ã®å€¤ãŒå·®åˆ†æ¤œå‡ºç”¨ãƒ‡ãƒ¼ã‚¿ã¨ç•°ãªã‚‹è¡Œã‚’æŠ½å‡º
    email_changed_rows = []
    
    for idx, main_row in main_data.iterrows():
        # ã‚¹ãƒ©ãƒƒã‚°ã§ãƒãƒƒãƒãƒ³ã‚°
        main_slug = normalize_value(main_row.get('ã‚¹ãƒ©ãƒƒã‚°', ''))
        
        if main_slug:  # ã‚¹ãƒ©ãƒƒã‚°ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿å‡¦ç†
            # å·®åˆ†æ¤œå‡ºç”¨ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åŒã˜ã‚¹ãƒ©ãƒƒã‚°ã®è¡Œã‚’å–å¾—
            original_row = original_data[original_data['ã‚¹ãƒ©ãƒƒã‚°'] == main_slug]
            
            if not original_row.empty:
                # ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã®æ¯”è¼ƒ
                main_email = normalize_value(main_row.get('ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç™ºè¡Œã®ç™»éŒ²ç”¨ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹', ''))
                original_email = normalize_value(original_row.iloc[0].get('ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç™ºè¡Œã®ç™»éŒ²ç”¨ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹', ''))
                
                if main_email != original_email:
                    email_changed_rows.append({
                        'index': idx,
                        'main_row': main_row,
                        'main_email': main_email,
                        'original_email': original_email
                    })
    
    # 2. æŠ½å‡ºã—ãŸãƒ‡ãƒ¼ã‚¿ã®ã†ã¡ã€ã€Œä»£è¡¨è€…ã€åˆ—ã®å€¤ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ã€Œã‚¹ãƒ©ãƒƒã‚°ã€åˆ—ã¨ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’æ¢ã™
    for change_info in email_changed_rows:
        main_row = change_info['main_row']
        representative_slug = normalize_value(main_row.get('ä»£è¡¨è€…', ''))
        
        if representative_slug:  # ä»£è¡¨è€…ã‚¹ãƒ©ãƒƒã‚°ãŒå­˜åœ¨ã™ã‚‹å ´åˆ
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ä¸€è‡´ã™ã‚‹ã‚¹ãƒ©ãƒƒã‚°ã‚’æ¢ã™
            matching_user = user_data[user_data['ã‚¹ãƒ©ãƒƒã‚°'] == representative_slug]
            
            if not matching_user.empty:
                # 3. ä¸€è‡´ã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ã€Œåå‰ã€ã€Œãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã€ã‚’æ›´æ–°
                user_row = matching_user.iloc[0]
                
                # ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ–°ã—ã„å€¤ã‚’å–å¾—
                new_name = normalize_value(main_row.get('ã‚µãƒ¼ã‚¯ãƒ«å', ''))
                new_email = change_info['main_email']
                
                # ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’å–å¾—
                current_name = normalize_value(user_row.get('åå‰', ''))
                current_email = normalize_value(user_row.get('ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹', ''))
                
                # å®Ÿéš›ã«å¤‰æ›´ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                name_changed = new_name != current_name
                email_changed = new_email != current_email
                
                if name_changed or email_changed:
                    # ä¿®æ­£ã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
                    modified_user = {
                        'åå‰': new_name if new_name else current_name,
                        'ã‚¹ãƒ©ãƒƒã‚°': representative_slug,
                        'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹': new_email if new_email else current_email,
                        'è‡ªå·±ç´¹ä»‹': normalize_value(user_row.get('è‡ªå·±ç´¹ä»‹', '')),
                        'ç¨®é¡': normalize_value(user_row.get('ç¨®é¡', '')),
                        'Webã‚µã‚¤ãƒˆ': normalize_value(user_row.get('Webã‚µã‚¤ãƒˆ', '')),
                        'ç”»åƒ': normalize_value(user_row.get('ç”»åƒ', ''))
                    }
                    
                    modified_users_df = pd.concat([modified_users_df, pd.DataFrame([modified_user])], ignore_index=True)
                    
                    # ä¿®æ­£å¯¾è±¡è¡Œã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¨˜éŒ²
                    modified_row_indices.append(change_info['index'])
                    
                    # å·®åˆ†è¡¨ç¤ºç”¨ã®æƒ…å ±ã‚’è¨˜éŒ²
                    modification_details.append({
                        'ã‚µãƒ¼ã‚¯ãƒ«å': new_name,
                        'ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¹ãƒ©ãƒƒã‚°': representative_slug,
                        'åå‰å¤‰æ›´': f"ã€Œ{current_name}ã€â†’ã€Œ{new_name}ã€" if name_changed else "å¤‰æ›´ãªã—",
                        'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹å¤‰æ›´': f"ã€Œ{current_email}ã€â†’ã€Œ{new_email}ã€" if email_changed else "å¤‰æ›´ãªã—",
                        'å¤‰æ›´ç†ç”±': 'ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç™ºè¡Œã®ç™»éŒ²ç”¨ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹åˆ—ã®å·®åˆ†æ¤œå‡º'
                    })
    
    # å·®åˆ†ã‚’ç”»é¢è¡¨ç¤ºï¼ˆStreamlitã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜ï¼‰
    if modification_details:
        st.session_state.user_modification_details = modification_details
    
    return modified_users_df, modified_row_indices

def main():
    initialize_session_state()
    log_session_state_change("app_started", {})
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã®åˆ‡ã‚Šæ›¿ãˆã¨ä½¿ã„æ–¹ã‚’è¿½åŠ 
    with st.sidebar:
        st.session_state.debug_mode = st.checkbox("ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰", value=st.session_state.debug_mode)
        
        # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ï¼ˆæ§ãˆã‚ã«è¡¨ç¤ºï¼‰
        st.markdown("---")
        st.caption("v2.0 - 2025/07/03")
    
    st.title("è‚²å…ã‚µãƒ¼ã‚¯ãƒ«æƒ…å ±å‡¦ç†ã‚¢ãƒ—ãƒª")
    
    # ã‚¿ãƒ–ã®ä½œæˆ
    tab1, tab2 = st.tabs([
        "ãƒ‡ãƒ¼ã‚¿ä¿®æ­£ç”¨ã‚¨ã‚¯ã‚»ãƒ«ä½œæˆ",
        "ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ"
    ])
    
    # ã‚¿ãƒ–ã®å†…å®¹ã‚’è¡¨ç¤º
    with tab1:
        # ãƒ‡ãƒ¼ã‚¿ä¿®æ­£ç”¨ã‚¨ã‚¯ã‚»ãƒ«ä½œæˆã‚¿ãƒ–ã®ä½¿ã„æ–¹ã‚’ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«è¡¨ç¤º
        with st.sidebar:
            st.markdown("---")
            st.markdown("### ğŸ“Š ãƒ‡ãƒ¼ã‚¿ä¿®æ­£ç”¨ã‚¨ã‚¯ã‚»ãƒ«ä½œæˆã®ä½¿ã„æ–¹")
            st.markdown("""
            1. è‚²å…ã‚µãƒ¼ã‚¯ãƒ«CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            2. æ–½è¨­æƒ…å ±CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            3. å…ˆæœˆåˆ†ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆExcelãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            4. è‡ªæ²»ä½“åã‚’å…¥åŠ›ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼šåŒ—ä¹å·å¸‚æ§˜ï¼‰
            5. ã€Œå‡¦ç†é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
            6. å‡¦ç†ãŒå®Œäº†ã—ãŸã‚‰ã€Œå‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€ãƒœã‚¿ãƒ³ãŒè¡¨ç¤ºã•ã‚Œã‚‹
            7. ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸExcelãƒ•ã‚¡ã‚¤ãƒ«ã§ä¿®æ­£ä½œæ¥­ã‚’è¡Œã†
            """)
        
        show_modification_excel_page()
    
    with tab2:
        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆã‚¿ãƒ–ã®ä½¿ã„æ–¹ã‚’ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«è¡¨ç¤º
        with st.sidebar:
            st.markdown("---")
            st.markdown("### ğŸ“‹ ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆã®ä½¿ã„æ–¹")
            st.markdown("""
            1. ä¿®æ­£æ¸ˆã¿Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            2. å¿…è¦ã«å¿œã˜ã¦ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹è¡Œæ•°ã‚’èª¿æ•´
            3. æ–½è¨­æƒ…å ±CSVãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            4. ã€Œãƒ‡ãƒ¼ã‚¿æ¤œè¨¼é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
            5. æ¤œè¨¼çµæœã‚’ç¢ºèª
               - ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹å ´åˆï¼šã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£ã—ã¦ã‹ã‚‰å†åº¦æ¤œè¨¼
               - ã‚¨ãƒ©ãƒ¼ãŒ0ä»¶ã®å ´åˆï¼šæ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã«é€²ã‚€
            6. **ã‚¨ãƒ©ãƒ¼ãŒ0ä»¶ã®å ´åˆã®ã¿**ã€Œã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆé–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
            7. ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ãŒä½œæˆã•ã‚ŒãŸã‚‰ã€å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            """)
        
        show_import_data_page()

if __name__ == "__main__":
    main() 